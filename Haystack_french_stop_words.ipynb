{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52e781efaa004e87b88cc13f9b89bed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9992a73b9b2f4c3db1697b981ed6cd50",
              "IPY_MODEL_5650adb8624f43dd8ddd3dd62626adbc",
              "IPY_MODEL_1d11b738197e4a408f1aac8434dcc343"
            ],
            "layout": "IPY_MODEL_4115e57fd25e43bc9dfe7a4129bf6ccd"
          }
        },
        "9992a73b9b2f4c3db1697b981ed6cd50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89449c49276f437e910f6ef4cc084634",
            "placeholder": "​",
            "style": "IPY_MODEL_01c21f089f524656bb0d2e979efc6ce6",
            "value": "Downloading: 100%"
          }
        },
        "5650adb8624f43dd8ddd3dd62626adbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea3d63391d0403f97889ea0b5a0b2e0",
            "max": 515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46a77b393303454baedb7760710d677a",
            "value": 515
          }
        },
        "1d11b738197e4a408f1aac8434dcc343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1673edea5f914a85a1236c7895e3b3f4",
            "placeholder": "​",
            "style": "IPY_MODEL_db27a5882fba48fd90ea585f2f385c15",
            "value": " 515/515 [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "4115e57fd25e43bc9dfe7a4129bf6ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89449c49276f437e910f6ef4cc084634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c21f089f524656bb0d2e979efc6ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea3d63391d0403f97889ea0b5a0b2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a77b393303454baedb7760710d677a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1673edea5f914a85a1236c7895e3b3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db27a5882fba48fd90ea585f2f385c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ccab23d79564088be976c3b202935aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_244ca366a0a74cc59eaaf2c9b3e14b12",
              "IPY_MODEL_54c4cfac032244489ac0945c0657db02",
              "IPY_MODEL_6eaf4cece883445c97f47564197c067f"
            ],
            "layout": "IPY_MODEL_d76c2c6ee78142f88958228d2034e51f"
          }
        },
        "244ca366a0a74cc59eaaf2c9b3e14b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66924a9734d4bbab8aeb1c03b913f84",
            "placeholder": "​",
            "style": "IPY_MODEL_1de9c11a77524c25858a8d750ed22cb8",
            "value": "Downloading: 100%"
          }
        },
        "54c4cfac032244489ac0945c0657db02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6483728a854bbf894a73fca9a38fb3",
            "max": 442545449,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a23e3c1eac84fd19d4e742511c740a2",
            "value": 442545449
          }
        },
        "6eaf4cece883445c97f47564197c067f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e339d7ec554b4ced898f6fcb5fa43266",
            "placeholder": "​",
            "style": "IPY_MODEL_25a3aacc7f9046c98282dd6312b87909",
            "value": " 443M/443M [00:10&lt;00:00, 35.5MB/s]"
          }
        },
        "d76c2c6ee78142f88958228d2034e51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66924a9734d4bbab8aeb1c03b913f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de9c11a77524c25858a8d750ed22cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6483728a854bbf894a73fca9a38fb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a23e3c1eac84fd19d4e742511c740a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e339d7ec554b4ced898f6fcb5fa43266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a3aacc7f9046c98282dd6312b87909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d0062a9c1045719c487e1505b29688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_506dbb6525ad498eaae16fc3888ccd8d",
              "IPY_MODEL_e4004111d9a14698981dd717c576bca8",
              "IPY_MODEL_668f34c8e68349dda6e12c16e6ea09bc"
            ],
            "layout": "IPY_MODEL_9416c6bea486422a82ca76eb0cba6646"
          }
        },
        "506dbb6525ad498eaae16fc3888ccd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9537b7a64c747b693d582525ff00446",
            "placeholder": "​",
            "style": "IPY_MODEL_8342180b43454a29bafc98d615afe130",
            "value": "Downloading: 100%"
          }
        },
        "e4004111d9a14698981dd717c576bca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd898c7f67e489b82070fd2c4a93d46",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_961d4042fc7f490e8baed99fbaecfda4",
            "value": 24
          }
        },
        "668f34c8e68349dda6e12c16e6ea09bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66bc14c4048f4c61837e60273f7ce9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_20e8819deead42f78f246f1a19c981f1",
            "value": " 24.0/24.0 [00:00&lt;00:00, 1.56kB/s]"
          }
        },
        "9416c6bea486422a82ca76eb0cba6646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9537b7a64c747b693d582525ff00446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8342180b43454a29bafc98d615afe130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcd898c7f67e489b82070fd2c4a93d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961d4042fc7f490e8baed99fbaecfda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66bc14c4048f4c61837e60273f7ce9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e8819deead42f78f246f1a19c981f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3c4815269be42b3afbd8007212db9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03c7c650ded24e0d898d6844ebf25b1e",
              "IPY_MODEL_748114b72a6f44beacef1a8dc04f73d9",
              "IPY_MODEL_7782c84750ea4834aeb9d0854714e120"
            ],
            "layout": "IPY_MODEL_5172822f6cc241bea2221f739b4440bf"
          }
        },
        "03c7c650ded24e0d898d6844ebf25b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e89cf040b634c41af45bf813a8c299f",
            "placeholder": "​",
            "style": "IPY_MODEL_97045a243dd74c44bcec0ce6ee6ed8f0",
            "value": "Downloading: 100%"
          }
        },
        "748114b72a6f44beacef1a8dc04f73d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ddf69596254504bb199d30c7bb61ae",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cc123b1c9e345b0b3e6825efc850609",
            "value": 810912
          }
        },
        "7782c84750ea4834aeb9d0854714e120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa27427b9a84feba3b229741b335029",
            "placeholder": "​",
            "style": "IPY_MODEL_44df1829dc5b4cc4a77ff47a5a91c24b",
            "value": " 811k/811k [00:00&lt;00:00, 879kB/s]"
          }
        },
        "5172822f6cc241bea2221f739b4440bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e89cf040b634c41af45bf813a8c299f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97045a243dd74c44bcec0ce6ee6ed8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ddf69596254504bb199d30c7bb61ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc123b1c9e345b0b3e6825efc850609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfa27427b9a84feba3b229741b335029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44df1829dc5b4cc4a77ff47a5a91c24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60626d9535e4a9093370418e0e4c2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7225d02ee71b4d10b7ba667476a4bd8b",
              "IPY_MODEL_bc37c295fbe445bdb78e8ef92c610367",
              "IPY_MODEL_c604c9f8790942fd80d5755c3ada8913"
            ],
            "layout": "IPY_MODEL_ef2b864dc372472d9d5718d4c751da05"
          }
        },
        "7225d02ee71b4d10b7ba667476a4bd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a550b9d39acc40da972a937cae93a74d",
            "placeholder": "​",
            "style": "IPY_MODEL_777c68e7b3f04ed2b526b2be34251a7c",
            "value": "Downloading: 100%"
          }
        },
        "bc37c295fbe445bdb78e8ef92c610367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8667cea1494be8b199d1bd72e6acae",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_906c23c58119416f9e201846fb2c4a35",
            "value": 210
          }
        },
        "c604c9f8790942fd80d5755c3ada8913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66cd48aff19243aa9924a4fe5fd06037",
            "placeholder": "​",
            "style": "IPY_MODEL_736fffeb753844f3952e8cb0b31731ff",
            "value": " 210/210 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "ef2b864dc372472d9d5718d4c751da05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a550b9d39acc40da972a937cae93a74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777c68e7b3f04ed2b526b2be34251a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd8667cea1494be8b199d1bd72e6acae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906c23c58119416f9e201846fb2c4a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66cd48aff19243aa9924a4fe5fd06037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736fffeb753844f3952e8cb0b31731ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8466665e08e4c55ad16239e265574b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c12b196da2844d0a89bb333be851ef5e",
              "IPY_MODEL_9a7b315ba0494798907e1aa1fe4d4151",
              "IPY_MODEL_21bfe64b40594407973415f23f29531e"
            ],
            "layout": "IPY_MODEL_94c1395194f840adae51463734c95e49"
          }
        },
        "c12b196da2844d0a89bb333be851ef5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43028f6d57c4ec0bbbb9600a5908aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2c33555b1254e4ba0637c153604dc02",
            "value": "Inferencing Samples: 100%"
          }
        },
        "9a7b315ba0494798907e1aa1fe4d4151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba89333024045a2bd862487851109d1",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0536e1e083d94f8fb0b74f3771a60fd9",
            "value": 4
          }
        },
        "21bfe64b40594407973415f23f29531e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688a3b06bcb349fba1fd44769a31c27a",
            "placeholder": "​",
            "style": "IPY_MODEL_6a49164acd2b4611a85f8bbf6923f022",
            "value": " 4/4 [00:05&lt;00:00,  1.09 Batches/s]"
          }
        },
        "94c1395194f840adae51463734c95e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43028f6d57c4ec0bbbb9600a5908aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c33555b1254e4ba0637c153604dc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ba89333024045a2bd862487851109d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0536e1e083d94f8fb0b74f3771a60fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "688a3b06bcb349fba1fd44769a31c27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a49164acd2b4611a85f8bbf6923f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/MIMICData"
      ],
      "metadata": {
        "id": "BeboKMBRjk1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/TESTE.zip -d /content/MIMICData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnh9gG0Xkn_Z",
        "outputId": "a2c263a8-852f-479f-e37c-ed8399d689dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/TESTE.zip\n",
            "   creating: /content/MIMICData/TESTE/\n",
            "  inflating: /content/MIMICData/TESTE/fichier_1.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_10.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_2.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_3.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_4.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_5.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_6.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_7.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_8.txt  \n",
            "  inflating: /content/MIMICData/TESTE/fichier_9.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/MIMICData/TESTE/fichier_1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjF1O-0uvb3A",
        "outputId": "519af171-38e8-4dfe-e322-0c4918e37ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'intelligence artificielle (IA) est un « ensemble de théories et de techniques mises en œuvre en vue de réaliser des machines capables de simuler l'intelligence humaine »1.\r\n",
            "\r\n",
            "Elle englobe donc un ensemble de concepts et de technologies, plus qu'une discipline autonome constituée2. Des instances, telle la CNIL, notant le peu de précision de la \r\n",
            "définition de l'IA, l'ont présentée comme « le grand mythe de notre temps »3.\r\n",
            "\r\n",
            "Souvent classée dans le groupe des mathématiques et des sciences cognitives, elle fait appel à la neurobiologie computationnelle (particulièrement aux réseaux neuronaux) \r\n",
            "et à la logique mathématique (partie des mathématiques et de la philosophie). Elle utilise des méthodes de résolution de problèmes à forte complexité logique ou algorithmique.\r\n",
            " Par extension, elle comprend, dans le langage courant, les dispositifs imitant ou remplaçant l'homme dans certaines mises en œuvre de ses fonctions cognitives4.\r\n",
            "\r\n",
            "Ses finalités et enjeux ainsi que son développement suscitent, depuis l'apparition du concept, de nombreuses interprétations, fantasmes ou inquiétudes s'exprimant tant dans \r\n",
            "les récits ou films de science-fiction que dans les essais philosophiques5. Si des outils relevant d'intelligences artificielles spécialisées ont fait leurs preuves, \r\n",
            "la réalité semble encore tenir l'intelligence artificielle généraliste loin des performances du vivant ; ainsi, l'IA reste encore bien inférieure au chat dans toutes ses \r\n",
            "aptitudes naturelles6.\r\n",
            "Le terme « intelligence artificielle », créé par John McCarthy, est souvent abrégé par le sigle « IA » (ou « AI » en anglais, pour Artificial Intelligence). Il est défini par l’un de ses créateurs, Marvin Lee Minsky, comme « la construction de programmes informatiques qui s’adonnent à des tâches qui sont, pour l’instant, accomplies de façon plus satisfaisante par des êtres humains car elles demandent des processus mentaux de haut niveau tels que : l’apprentissage perceptuel, l’organisation de la mémoire et le raisonnement critique »a,7. On y trouve donc le côté « artificiel » atteint par l'usage des ordinateurs ou de processus électroniques élaborés et le côté « intelligence » associé à son but d'imiter le comportement. Cette imitation peut se faire dans le raisonnement, par exemple dans les jeux ou la pratique des mathématiques, dans la compréhension des langues naturelles, dans la perception : visuelle (interprétation des images et des scènes), auditive (compréhension du langage parlé) ou par d'autres capteurs, dans la commande d'un robot dans un milieu inconnu ou hostile.\r\n",
            "\r\n",
            "Même si elles respectent globalement la définition de Minsky, certaines définitions de l'IA varient sur deux points fondamentaux8 :\r\n",
            "\r\n",
            "les définitions qui lient l'IA à un aspect humain de l'intelligence, et celles qui la lient à un modèle idéal d'intelligence, non forcément humaine, nommée rationalité ;\r\n",
            "les définitions qui insistent sur le fait que l'IA a pour but d'avoir toutes les apparences de l'intelligence (humaine ou rationnelle), et celles qui insistent sur le fait que le fonctionnement interne du système d'IA doit ressembler également à celui de l'être humain et être au moins aussi rationnel.\r\n",
            "Historique:\r\n",
            "Historiquement, l'idée d'intelligence artificielle semble émerger dans les années 1950 quand Alan Turing se demande si une machine peut « penser ». Dans l'article « Computing Machinery and Intelligence » (Mind, octobre 1950)9, Turing explore ce problème et propose une expérience (maintenant dite test de Turing) visant à trouver à partir de quand une machine deviendrait « consciente ». Il développe ensuite cette idée dans plusieurs forums, dans la conférence « L'intelligence de la machine, une idée hérétique »10, dans la conférence qu'il donne à la BBC 3e programme le 15 mai 1951 « Les calculateurs numériques peuvent-ils penser ? »11 ou la discussion avec M.H.A. Newman, Sir Geoffrey Jefferson et R.B. Braithwaite les 14 et 23 janvier 1952 sur le thème « Les ordinateurs peuvent-ils penser ? »12.\r\n",
            "\r\n",
            "Une autre origine probable est la publication, en 1949, par Warren Weaver d'un mémorandum sur la traduction automatique des langues13 qui suggère qu'une machine puisse faire une tâche qui relève typiquement de l'intelligence humaine.\r\n",
            "\r\n",
            "Le développement des techniques informatiques (augmentation de la puissance de calcul) aboutit ensuite à plusieurs avancées :\r\n",
            "\r\n",
            "dans les années 1980, l'apprentissage automatique se développe, notamment avec la renaissance du connexionnisme. L'ordinateur commence à déduire des « règles à suivre » en analysant seulement des données14,15 ;\r\n",
            "parallèlement, des algorithmes « apprenants » sont créés qui préfigurent les futurs réseaux de neurones (l'apprentissage par renforcement, les machines à vecteurs de support, etc.). Ceci permet par exemple en mai 1997 à l’ordinateur Deep Blue de battre Garry Kasparov au jeu d'échecs16 lors d'un match revanche de six parties ;\r\n",
            "l'intelligence artificielle devient un domaine de recherche international, marquée par une conférence au Dartmouth College à l’été 195617,18 à laquelle assistaient ceux qui vont marquer la discipline ;\r\n",
            "depuis les années 1960, la recherche se fait principalement aux États-Unis, notamment à l'université Stanford sous l'impulsion de John McCarthy19, au MIT sous celle de Marvin Minsky20, à l'université Carnegie-Mellon sous celle de Allen Newell et Herbert Simon21 et à l'université d'Édimbourg sous celle de Donald Michie22, en Europe et en Chine, ainsi qu'au Japon avec le projet « ordinateurs de cinquième génération (en) » du gouvernement. En France, l'un des pionniers est Jacques Pitrat23 ;\r\n",
            "dans les années 2000, le Web 2.0, le big data et de nouvelles puissances et infrastructures de calcul permettent à certains ordinateurs d'explorer des masses de données sans précédent ; c'est l'apprentissage profond (« deep learning »), dont l'un des pionniers est le français Yann Le Cun24.\r\n",
            "Les bornes de ce domaine varient, ainsi optimiser un itinéraire était considéré comme un problème d'intelligence artificielle dans les années 1950 et n'est plus considéré aujourd’hui que comme un simple problème d'algorithmie25.\r\n",
            "\r\n",
            "Vers 2015, le secteur de l'intelligence artificielle cherche à relever quatre défis : la perception visuelle, la compréhension du langage naturel écrit ou parlé, l'analyse automatique du langage et la prise de décision autonome26. Produire et organiser des données nombreuses et de qualité, c'est-à-dire corrélées, complètes, qualifiées (sourcées, datées, géoréférencées…), historisées est un autre enjeu. La capacité déductive et de généralisation pertinente d'un ordinateur, à partir de peu de données ou d'un faible nombre d'évènements, est un autre objectif, plus lointain26.\r\n",
            "\r\n",
            "Entre 2010 et 2016, les investissements auraient été décuplés, atteignant une dizaine de milliards de dollars en 201627.\r\n",
            "\r\n",
            "Précurseurs\r\n",
            "Si les progrès de l’intelligence artificielle sont récents, ce thème de réflexion est tout à fait ancien, et il apparaît régulièrement au cours de l’histoire. Les premiers signes d’intérêt pour une intelligence artificielle et les principaux précurseurs de cette discipline sont les suivants.\r\n",
            "\r\n",
            "Automates:\r\n",
            "Une des plus anciennes traces du thème de « l’homme dans la machine » date de 800 avant notre ère, en Égypte. La statue du dieu Amon levait le bras pour désigner le nouveau pharaon parmi les prétendants qui défilaient devant lui, puis elle « prononçait » un discours de consécration. Les Égyptiens étaient probablement conscients de la présence d’un prêtre actionnant un mécanisme et déclarant les paroles sacrées derrière la statue, mais cela ne semblait pas être pour eux contradictoire avec l’incarnation de la divinité. Vers la même époque, Homère, dans L'Iliade (XVIII, 370–421), décrit les automates réalisés par le dieu forgeron Héphaïstos : des trépieds munis de roues en or, capables de porter des objets jusqu’à l’Olympe et de revenir seuls dans la demeure du dieu ; ou encore, deux servantes forgées en or qui l’assistent dans sa tâche. De même, le Géant de bronze Talos, gardien des rivages de la Crète, était parfois considéré comme une œuvre du dieu.\r\n",
            "\r\n",
            "Vitruve, architecte romain, décrit l’existence entre le iiie et le ier siècle avant notre ère, d’une école d’ingénieurs fondée par Ctesibius à Alexandrie, et concevant des mécanismes destinés à l’amusement tels des corbeaux qui chantaient. Héron L'Ancien décrit dans son traité « Automates », un carrousel animé grâce à la vapeur et considéré comme anticipant les machines à vapeur. Les automates disparaissent ensuite jusqu’à la fin du Moyen Âge. On a prêté à Roger Bacon la conception d'automates doués de la parole; en fait, probablement de mécanismes simulant la prononciation de certains mots simples.\r\n",
            "\r\n",
            "Léonard de Vinci a construit en 1515 un automate en forme de lion pour amuser le roi de France, François I28. Gio Battista Aleotti et Salomon de Caus, eux, ont construit des \r\n",
            "oiseaux artificiels et chantants, des flûtistes mécaniques, des nymphes, des dragons et des satyres animés pour égayer des fêtes aristocratiques, des jardins et des grottes. \r\n",
            "René Descartes, lui, aurait conçu en 1649 un automate qu’il appelait « ma fille Francine ». Il conduit par ailleurs une réflexion d’un modernisme étonnant sur les différences\r\n",
            " entre la nature des automates, et celles d’une part des animaux (pas de différence) et d’autre part celle des hommes (pas d’assimilation). Ces analyses en font le précurseur\r\n",
            " méconnu d’un des principaux thèmes de la science-fiction : l'indistinction entre le vivant et l’artificiel, entre les hommes et les robots, les androïdes ou les intelligences\r\n",
            " artificielles.\r\n",
            "Jacques de Vaucanson a construit en 1738 un « canard artificiel de cuivre doré, qui boit, mange, cancane, barbote et digère comme un vrai canard ». Il était possible de programmer les mouvements de cet automate, grâce à des pignons placés sur un cylindre gravé, qui contrôlaient des baguettes traversant les pattes du canard. L’automate a été exposé pendant plusieurs années en France, en Italie et en Angleterre, et la transparence de l’abdomen permettait d’observer le mécanisme interne. Le dispositif permettant de simuler la digestion et d’expulser une sorte de bouillie verte fait l’objet d’une controverse. Certains commentateurs estiment que cette bouillie verte n’était pas fabriquée à partir des aliments ingérés, mais préparée à l’avance. D’autres estiment que cet avis n’est fondé que sur des imitations du canard de Vaucanson. L’incendie du musée de Nijni Novgorod en Russie, vers 1879, a détruit cet automate29.\r\n",
            "\r\n",
            "Les artisans Pierre et Louis Jaquet-Droz fabriquèrent parmi les meilleurs automates fondés sur un système purement mécanique, avant le développement des dispositifs électromécaniques. Certains de ces automates, par un système de cames multiples, étaient capables d'écrire un petit billet (toujours le même). Enfin, Les Contes d'Hoffmann (et ballet) L'Homme au sable décrit une poupée mécanique dont s'éprend le héros.\r\n",
            "\r\n",
            "Pensée automatique:\r\n",
            "Une des premières tentatives de formalisation de la pensée connue est le zairja, mécanisme qu'utilisaient les astrologues arabe pour générer des idées supposées logiques, dont l'invention est attribuée à Abu al-Abbas as-Sabti au xiie siècle. Raymond Lulle s'en est probablement inspiré pour mettre au point son Ars Magna30. Missionnaire, philosophe, et théologien espagnol du xiiie siècle, il essaya lui aussi de générer des idées grâce à un système mécanique. Il combinait aléatoirement des concepts grâce à une sorte de règle à calcul, sur laquelle pivotaient des disques concentriques gravés de lettres et de symboles philosophiques. Il fondait sa méthode sur l’identification de concepts de base, puis leur combinaison mécanique soit entre eux, soit avec des idées connexes. Raymond Lulle l'appliqua à la métaphysique, puis à la morale, à la médecine et à l’astrologie. Mais il n’utilisait que la logique déductive, ce qui ne permettait pas à son système d’acquérir un apprentissage, ni davantage de remettre en cause ses principes de départ : seule la logique inductive le permet.\r\n",
            "\r\n",
            "Gottfried Wilhelm Leibniz, au xviie siècle, a imaginé un calcul pensant (calculus rationator), en assignant un nombre à chaque concept. La manipulation de ces nombres aurait permis de résoudre les questions les plus difficiles, et même d’aboutir à un langage universel. Leibniz a toutefois démontré que l’une des principales difficultés de cette méthode, également rencontrée dans les travaux modernes sur l’intelligence artificielle, est l’interconnexion de tous les concepts, ce qui ne permet pas d’isoler une idée de toutes les autres pour simplifier les problèmes liés à la pensée.\r\n",
            "\r\n",
            "George Boole a inventé la formulation mathématique des processus fondamentaux du raisonnement, connue sous le nom d’algèbre de Boole. Il était conscient des liens de ses travaux avec les mécanismes de l’intelligence, comme le montre le titre de son principal ouvrage paru en 1854 : Les Lois de la pensée31 (The laws of thought), sur l’algèbre booléenne.\r\n",
            "\r\n",
            "Gottlob Frege perfectionna le système de Boole en formalisant le concept de prédicat, qui est une entité logique soit vraie, soit fausse (toute maison a un propriétaire), mais contenant des variables non logiques, n’ayant en soi aucun degré de vérité (maison, propriétaire). Cette formalisation eut une grande importance puisqu'elle permit de démontrer des théorèmes généraux, simplement en appliquant des règles typographiques à des ensembles de symboles. La réflexion en langage courant ne portait plus que sur le choix des règles à appliquer. Par ailleurs, l’utilisateur joue un rôle important puisqu'il connaît le sens des symboles qu’il a inventés et ce sensb n'est pas toujours formalisé, ce qui ramène au problème de la signification en intelligence artificielle, et de la subjectivité des utilisateurs.\r\n",
            "\r\n",
            "Bertrand Russell et Alfred North Whitehead publièrent au début du xxe siècle un ouvrage intitulé Principia Mathematica, dans lequel ils résolvent des contradictions internes à la théorie de Gottlob Frege. Ces travaux laissaient espérer d’aboutir à une formalisation complète des mathématiques32.\r\n",
            "\r\n",
            "Kurt Gödel démontre au contraire que les mathématiques resteront une construction ouverte, en publiant en 1931 un article intitulé « Des propositions formellement indécidables contenues dans les Principia mathematica et autres systèmes similaires ». Sa démonstration est qu’à partir d’une certaine complexité d’un système, on peut y créer plus de propositions logiques qu’on ne peut en démontrer vraies ou fausses. L’arithmétique, par exemple, ne peut trancher par ses axiomes si on doit accepter des nombres dont le carré soit -1. Ce choix reste arbitraire et n’est en rien lié aux axiomes de base. Le travail de Gödel suggère qu’on pourra créer ainsi un nombre arbitraire de nouveaux axiomes, compatibles avec les précédents, au fur et à mesure qu’on en aura besoin. Si l'arithmétique est démontrée incomplète, le calcul des prédicats (logique formelle) est au contraire démontré par Gödel comme complet33.\r\n",
            "\r\n",
            "Alan Turing invente des machines abstraites et universelles (rebaptisées les machines de Turing), dont les ordinateurs modernes sont considérés comme des concrétisations. Il démontre l’existence de calculs qu’aucune machine ne peut faire (un humain pas davantage, dans les cas qu'il cite), sans pour autant que cela constitue pour Turing un motif pour douter de la faisabilité de machines pensantes répondant aux critères du test de Turing.\r\n",
            "\r\n",
            "Irving John Good34, Myron Tribus et E.T. Jaynes35 ont décrit de façon très claire les principes assez simples d’un robot à logique inductive utilisant les principes de l’inférence bayésienne pour enrichir sa base de connaissances sur la base du Théorème de Cox-Jaynes. Ils n’ont malheureusement pas traité la question de la façon dont on pourrait stocker ces connaissances sans que le mode de stockage entraîne un biais cognitif. Le projet est voisin de celui de Raymond Lulle, mais fondé cette fois-ci sur une logique inductive, et donc propre à résoudre quelques problèmes ouverts.\r\n",
            "\r\n",
            "Des chercheurs comme Alonzo Church ont posé des limites pratiques aux ambitions de la raison, en orientant la recherche (Herbert Simon, Michael Rabin, Stephen Cook) vers l’obtention des solutions en temps fini, ou avec des ressources limitées, ainsi que vers la catégorisation des problèmes selon des classes de difficulté (en rapport avec les travaux de Cantor sur l’infini)Faits marquants depuis les années 2000\r\n",
            "L'intelligence artificielle est un sujet d'actualité au xxie siècle. En 2004, l'Institut Singularity a lancé une campagne Internet appelée « Trois lois dangereuses » : « Three Laws Unsafe » (en lien avec les trois lois d'Asimov) pour sensibiliser aux questions de la problématique de l'intelligence artificielle et l'insuffisance des lois d'Asimov en particulier. (Singularity Institute for Artificial Intelligence 2004)36.\r\n",
            "\r\n",
            "En 2005, le projet Blue Brain est lancé, il vise à simuler le cerveau des mammifères. Il s'agit d'une des méthodes envisagées pour réaliser une IA. Ils annoncent de plus comme objectif de fabriquer, dans dix ans, le premier « vrai » cerveau électronique37. En mars 2007, le gouvernement sud-coréen annonce que plus tard dans l'année, il émettrait une charte sur l'éthique des robots, afin de fixer des normes pour les utilisateurs et les fabricants. Selon Park Hye-Young, du ministère de l'Information et de la communication, la Charte reflète les trois lois d'Asimov : la tentative de définition des règles de base pour le développement futur de la robotique. En juillet 2009, en Californie une conférence organisée par l'Association for the Advancement of Artificial Intelligence (AAAI), où un groupe d'informaticiens se demande s'il devrait y avoir des limites sur la recherche qui pourrait conduire à la perte de l'emprise humaine sur les systèmes informatiques, et où il est également question de l'explosion de l'intelligence (artificielle) et du danger de la singularité technologique conduisant à un changement d'ère, ou de paradigme totalement en dehors du contrôle humain38,39.\r\n",
            "\r\n",
            "En 2009, le Massachusetts Institute of Technology (MIT) a lancé un projet visant à repenser la recherche en intelligence artificielle. Il réunira des scientifiques qui ont eu du succès dans des domaines distincts de l'IA. Neil Gershenfeld déclare « Nous voulons essentiellement revenir 30 ans en arrière, et de revoir quelques directions aujourd'hui gelées »40.\r\n",
            "\r\n",
            "En novembre 2009, l'US Air Force cherche à acquérir 2 200 PlayStation 341[réf. obsolète] pour utiliser le processeur cell à 7 ou 8 cœurs qu'elle contient dans le but d'augmenter les capacités de leur superordinateur constitué de 336 PlayStation 3 (total théorique 52,8 petaFLOPS en double précision). Le nombre sera réduit à 1 700 unités le 22 décembre 200942. Le projet vise le traitement vidéo haute-définition, et l'« informatique neuromorphique », ou la création de calculateurs avec des propriétés/fonctions similaires au cerveau humain41.\r\n",
            "\r\n",
            "Années 2010\r\n",
            "Le 27 janvier 2010, l'US Air Force demande l'aide de l'industrie pour développer une intelligence avancée de collecte d'information et avec la capacité de décision rapide pour aider les forces américaines pour attaquer ses ennemis rapidement à leurs points les plus vulnérables. L'US Air Force utilisera une intelligence artificielle, le raisonnement ontologique, et les procédures informatique basées sur la connaissance, ainsi que d'autres traitements de données avancés afin de frapper l'ennemi au meilleur point43. D'autre part, d’ici 2020, plus de mille bombardiers et chasseurs F-22 et F-35 de dernière génération, parmi plus de 2 500 avions militaires, commenceront à être équipés de sorte que, d’ici 2040, tous les avions de guerre américains soient pilotés par intelligence artificielle, en plus des 10 000 véhicules terrestres et des 7 000 dispositifs aériens commandés d'ores et déjà à distance44.\r\n",
            "\r\n",
            "Le 16 février 2011, Watson, le superordinateur conçu par IBM, remporte deux des trois manches du jeu télévisé Jeopardy! en battant largement ses deux concurrents humains en gains cumulés. Pour cette IA, la performance a résidé dans le fait de répondre à des questions de culture générale (et non un domaine technique précis) dans des délais très courts. En février 2016, l'artiste et designer Aaron Siegel propose de faire de Watson un candidat à l'élection présidentielle américaine afin de lancer le débat sur « le potentiel de l’intelligence artificielle dans la politique »45.\r\n",
            "\r\n",
            "En mai 2013, Google ouvre un laboratoire de recherches dans les locaux de la NASA. Grâce à un super calculateur quantique conçu par D-Wave Systems et qui serait d'après cette société 11 000 fois plus performant qu'un ordinateur actuel (de 2013)46, ils espèrent ainsi faire progresser l'intelligence artificielle, notamment l'apprentissage automatique. Raymond Kurzweil est engagé en décembre 2012 par Google afin de participer et d'améliorer l'apprentissage automatique des machines et des IA47.\r\n",
            "\r\n",
            "Entre 2014 et 2015, à la suite du développement rapide du deep learning, et à l'encontre des penseurs transhumanistes, quelques scientifiques et membres de la communauté high tech craignent que l'intelligence artificielle ne vienne à terme dépasser les performances de l'intelligence humaine. Parmi eux, l'astrophysicien britannique Stephen Hawking48, le fondateur de Microsoft Bill Gates49 et le PDG de Tesla Elon Musk50.\r\n",
            "\r\n",
            "Les géants de l'Internet s'intéressent de plus en plus à l'IA51. Le 3 janvier 2016, le patron de Facebook, Mark Zuckerberg, s’est donné pour objectif de l’année de « construire une intelligence artificielle simple pour piloter ma maison ou m’aider dans mon travail »52. Il avait déjà créé en 2013 le laboratoire Facebook Artifical Intelligence Research (FAIR) dirigé par le chercheur français Yann Le Cun et ouvert un laboratoire de recherche permanente dans le domaine à Paris53.\r\n",
            "\r\n",
            "Apple a de son côté récemment acquis plusieurs start-up du secteur (Perceptio, VocalIQ, Emotient et Turi)54.\r\n",
            "\r\n",
            "En janvier 2018, des modèles d'intelligence artificielle développés par Microsoft et Alibaba réussissent chacun de leur côté à battre les humains dans un test de lecture et de compréhension de l'université Stanford. Le traitement du langage naturel imite la compréhension humaine des mots et des phrases et permet maintenant aux modèles d'apprentissage automatique de traiter de grandes quantités d'informations avant de fournir des réponses précises aux questions qui leur sont posées55.\r\n",
            "\r\n",
            "En février 2019, l'institut de recherche OpenAI annonce avoir créé un programme d’intelligence artificielle capable de générer des textes tellement réalistes que cette technologie pourrait être dangereuse56,57. Si le logiciel est utilisé avec une intention malveillante, il peut générer facilement des fausses nouvelles très crédibles. Inquiet par l'utilisation qui pourrait en être faite, OpenAI préfère ne pas rendre public le code source du programme"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest release of Haystack in your own environment \n",
        "#! pip install farm-haystack\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfHt_ppk3aA",
        "outputId": "8f6abe8c-5954-404c-f9da-02927c1e92f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-22.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farm-haystack[colab]\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-install-ga_u5816/farm-haystack_6755acacc99e4864a64e1f89ccc209fd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-install-ga_u5816/farm-haystack_6755acacc99e4864a64e1f89ccc209fd\n",
            "  Resolved https://github.com/deepset-ai/haystack.git to commit d2bba4935b2ccfa7ef875815a4a1bf98afcedbc1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.5.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.3.3)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.19.6)\n",
            "Collecting elasticsearch<8,>=7.7\n",
            "  Downloading elasticsearch-7.17.8-py2.py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.0/386.0 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3\n",
            "  Downloading mmh3-3.0.0-cp38-cp38-manylinux2010_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<2.8.0,>=2.0.15\n",
            "  Downloading rapidfuzz-2.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.7.3)\n",
            "Collecting transformers[torch]==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.3.5)\n",
            "Collecting sentence-transformers>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.10.4)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (0.3.6)\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2\n",
            "  Downloading azure_ai_formrecognizer-3.2.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.4/228.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.64.1)\n",
            "Collecting quantulum3\n",
            "  Downloading quantulum3-0.8.1-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (9.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (2.25.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting posthog\n",
            "  Downloading posthog-2.2.0-py2.py3-none-any.whl (33 kB)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.7)\n",
            "Requirement already satisfied: pillow<=9.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.21.6)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.13.1+cu116)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.23.0\n",
            "  Downloading azure_core-1.26.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.8/173.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (4.4.0)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (2022.12.7)\n",
            "Collecting jarowinkler<2.0.0,>=1.2.0\n",
            "  Downloading jarowinkler-1.2.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.1/114.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (1.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab]) (0.14.1+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect->farm-haystack[colab]) (1.15.0)\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (7.1.2)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (9.0.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4.3)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.2.0)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.4.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2022.7)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.1.4)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.4.46)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.11.3)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (4.0.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff<2.0.0,>=1.10.0\n",
            "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx->farm-haystack[colab]) (4.9.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (from quantulum3->farm-haystack[colab]) (2.1.0)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tika->farm-haystack[colab]) (57.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (0.8.10)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<2,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.1.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->farm-haystack[colab]) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (1.4.4)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (1.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.56.4)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.39.1)\n",
            "Building wheels for collected packages: sentence-transformers, farm-haystack, langdetect, python-docx, seqeval, tika, databricks-cli, docopt\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=0bdd484e5897898167239f283d00b2cc02f1f44f137ccf85f9187a2806ff8a7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/b4/1c/7509ecb4c391a7be4cdf2ff04df077a568cd52471007e436e6\n",
            "  Building wheel for farm-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.13.0rc0-py3-none-any.whl size=603552 sha256=54bbb0585ae9018fda74becf25a0935387b51a341cf26705b818a2deb9ad3f04\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i9l22e5n/wheels/97/0d/ae/77cde17929fbf66c8320f19b30789acfe52e2312bb1d125be1\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=d8ac3e7c5fe09c7c78930915fde18978d72c513c7cc58b3e9b842fe21b4f008f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/af/97/539976921e53b1542a28f7160e511ac730b5d2cdcb41423ebb\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=cccb6f5d78627b2e5bc248fe272f3be159f1323ec0ac045c911527873107758a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/10/08/226d68e153dd4ec32713fbac0b1800b1311ff0adbc8eab3c06\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=81ecf8a24a8446e1ab46c42af3b6a4365f903a6ac03129436868c0da0d815198\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/30/9b/6b670dac34775f2b7cc4e9b172202e81fbb4f9cdb103c1ca66\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32642 sha256=3b95045cb4bf7ce7622226847bb855c6df177e7f4c77cd85485223c11cd822c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/24/b6/6d3480f25c91fcc9a55b4e76f180baf087ee2acd16e561a015\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142894 sha256=099a78ab97d57e98b87fa5153ab47258ef52e00f64df8ec5ab83771d180ac3b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/0b/75/44edb38430dc44de74324d6e72d91d0d14d21df90349767335\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=caba2f429ec528971d63717a37684ece2fb6e85d0d49ecceb1cd640911affd83\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cc/e3/f1e272f628fdb013d969acc99cfe2e031ea15b3efb74ffe842\n",
            "Successfully built sentence-transformers farm-haystack langdetect python-docx seqeval tika databricks-cli docopt\n",
            "Installing collected packages: tokenizers, sentencepiece, monotonic, mmh3, docopt, azure-common, websocket-client, urllib3, smmap, slicer, rank-bm25, querystring-parser, python-docx, pyjwt, num2words, Mako, langdetect, jarowinkler, isodate, importlib-metadata, gunicorn, backoff, requests, rapidfuzz, quantulum3, gitdb, elasticsearch, alembic, tika, shap, seqeval, posthog, huggingface-hub, gitpython, docker, databricks-cli, azure-core, transformers, msrest, mlflow, sentence-transformers, azure-ai-formrecognizer, farm-haystack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.2 azure-ai-formrecognizer-3.2.0 azure-common-1.1.28 azure-core-1.26.2 backoff-1.11.1 databricks-cli-0.17.4 docker-6.0.1 docopt-0.6.2 elasticsearch-7.17.8 farm-haystack-1.13.0rc0 gitdb-4.0.10 gitpython-3.1.30 gunicorn-20.1.0 huggingface-hub-0.11.1 importlib-metadata-5.2.0 isodate-0.6.1 jarowinkler-1.2.3 langdetect-1.0.9 mlflow-2.1.1 mmh3-3.0.0 monotonic-1.6 msrest-0.7.1 num2words-0.5.12 posthog-2.2.0 pyjwt-2.6.0 python-docx-0.8.11 quantulum3-0.8.1 querystring-parser-1.2.4 rank-bm25-0.2.2 rapidfuzz-2.7.0 requests-2.28.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 seqeval-1.2.2 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 tika-2.6.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.14 websocket-client-1.4.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "OL7bzEY0k62b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http, print_answers\n",
        "from haystack.nodes import FARMReader, TransformersReader"
      ],
      "metadata": {
        "id": "fq2R1OXtn-pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab / No Docker environments: Start Elasticsearch from source\n",
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "es_server = Popen(\n",
        "    [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        ")\n",
        "# wait until ES has started\n",
        "! sleep 30"
      ],
      "metadata": {
        "id": "4Gu5oSG_pehJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIOQqc9rplpx",
        "outputId": "36bf5fcb-b6a5-4354-bddb-6f680f70740e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by calling disable_telemetry() or by manually setting the environment variable  HAYSTACK_TELEMETRY_ENABLED as described for different operating systems on the documentation page. More information at https://docs.haystack.deepset.ai/docs/telemetry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_dir = \"/content/MIMICData\"\n",
        "\n",
        "\n",
        "# Convert files to dicts\n",
        "# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\n",
        "# It must take a str as input, and return a str.\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6DaLeJ2pzVx",
        "outputId": "5d54ddbf-1fcc-4631-9eac-b7a9a2ba85c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_8.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_2.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_9.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_6.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_10.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_7.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_5.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_3.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_4.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/TESTE/fichier_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[:2])\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC72vbFpp99e",
        "outputId": "6d91245f-f426-41b6-fb24-200df648ec1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Document: {'content': 'L’intelligence artificielle, ou IA, est entrain de changer le monde. Du domaine bancaire à l’entreprise, en passant par le secteur de l’agriculture ou encore la supply chain. Les applications de l‘IA sont nombreuses et variées ! Zoom sur l’intelligence artificielle en médecine à travers des exemples d’usage tel que l’aide au diagnostic.\\nUsage de l’IA en médecine pour l’aide au diagnostic des cancers\\nLa médecine l’a bien compris ! À l’image de l’hôpital parisien de la Pitié-Salpêtrière qui a rapidement adopté iBiopsy. Cette plateforme d’intelligence artificielle y révolutionne le traitement des pathologies, notamment le cancer du foie.\\nDes méthodes d’imagerie médicale, de deep learning et big data analytics permettent de mieux extraire les biomarqueurs de la progression de la maladie. L’objectif est d’améliorer le diagnostic du patient – donc sa prise en charge.\\n« On a une problématique, la détection du cancer. Et grâce à l’IA en médecine, on s’attache à y répondre » explique le professeur Olivier Lucidarme, chef de service Radiologie polyvalente et oncologique à la Pitié-Salpêtrière.\\nConcrètement, l’intelligence artificielle en médecine aide les professionnels de santé à extraire des images médicales, des informations utiles mais difficiles à repérer. Des fois même, indétectables à l’œil nu. Ces informations sont une mine d’or pour l’aide au diagnostic – résultats plus précoces et précis. « L’IA peut améliorer notre capacité de diagnostic, notamment des maladies rares, grâce à une capacité d’analyse des bases de données infinie » se réjouit Olivier Lucidarme.\\nL’intelligence artificielle permettra de basculer sur une médecine plus préventive.\\n Laurent Schlosser, directeur de la division Secteur Public chez Microsoft.”\\nLes pathologies sont mieux détectées et décelées plus tôt. Cela permet de s’attaquer plus rapidement aux pathologies et gagner du temps dans leur traitement. Voire même d’intervenir avant l’apparition d’une maladie.\\n« Le savoir médical, l’expertise du médecin reste le plus important, mais cette expertise est amplifiée grâce à l’intelligence artificielle. »\\nLa chirurgie futuriste grâce à l’intelligence artificielle\\nAutre fait révolutionnaire pour la médecine : l’IA au service de la chirurgie. Bien qu’elle ne soit pas encore déployée dans nos services de soins, elle devrait être l’innovation la plus importante dans les années à venir.\\nAprès plusieurs études et travaux sur l’IA en médecine, les présentations ont été faites avec des chirurgiens. Ces derniers ont ainsi su améliorer la présence de cette IA dans les blocs opératoires.\\nCette prouesse technologique propose plusieurs utilités. La plus courante serait de pouvoir observer le corps des patients comme s’ils étaient transparents. Cela permettrait aux chirurgiens de ne pas être gênés par un quelconque organe qui rendrait difficile l’accès à la zone à opérer.\\nCette pratique peut également faciliter l’aide au diagnostic médical. Et ainsi, réduire de façon considérable les risques d’erreurs. Des traitements personnalisés plus poussés seront alors envisageables sans trop perdre de temps.\\nL’invention la plus étonnante et la plus innovante reste l’intégration de l’IA à la pratique des chirurgiens. En effet, « la différence entre un jeune praticien et un expert, c’est l’expérience, la mémoire des cas traités par le passé » selon le directeur général de l’IHU, Jacques Marescaux. Le projet consiste à mettre une caméra vidéo qui enregistre les étapes d’une opération et des soins.\\nGrâce à des outils et des algorithmes bien pensés, le rôle de l’IA est d’alerter le chirurgien. Ces alertes ont lieu si le chirurgien se déconcentre ou s’il est sur le point d’effectuer un mouvement dangereux qui ne corresponds pas aux étapes enregistrées. C’est en quelque sorte une prédiction du risque qui facilite les opérations au bloc et garantit une meilleure sécurité pour les patients.\\nDes modèles ont déjà été mis sur le marché pour essai. L’apprentissage de la machine, après une cinquantaine d’interventions, a permis à l’ordinateur de définir les étapes de cette opération. Le plus remarquable est que l’ordinateur a pu signaler à un chirurgien qu’il prenait le mauvais outil au bout de 120 interventions.\\nL’intelligence artificielle en médecine pour répondre aux défis de demain\\nLes promesses technologiques ont toujours su faire leurs preuves en sciences et ont réussi à rassurer la population au cours des années. L’intelligence artificielle en médecine n’est pas un mauvais présage. Malgré les croyances, elle ne remplace pas l’intelligence humaine, au contraire, elle la complète.\\nDe nombreuses innovations technologiques vont encore apparaître dans la médecine, la recherche continue encore et toujours d’avancer.\\nL’intelligence artificielle en médecine s’avère donc très utile dans le traitement de tâches répétitives, à faible valeur ajoutée. Cela permet ainsi de décharger les médecins et de mieux utiliser leur temps. Autant de possibilités qui dessinent un nouveau monde, où l’IA aide les hommes à répondre aux grands défis d’aujourd’hui et de demain.\\nLaurent Schlosser (Microsoft) et Johan Brag (Median Technologies, société développant la plateforme d’IA iBiopsy) en discutent dans cette table ronde, animée par la journaliste Marion Moreau, lors de Microsoft experiences’17.\\nQuels usages pour l’intelligence artificielle en médecine ?\\nL’intelligence artificielle en médecine permet d’accompagner les professionnels de santé pour une meilleure prise en charge des patients. Cela peut se traduire dans un cadre de médecine préventive pour se soigner en amont de l’apparition des premiers symptômes. L’IA en médecine peut également faciliter les interventions en bloc opératoire via un impact sur le niveau de précision de l’acte chirurgical. Sans mentionner l’aide au diagnostic en amont d’un rendez-vous médical, l’assurance d’un suivi personnalisé, faciliter la recherche médicale, mieux structurer et traiter les données patients etc.', 'content_type': 'text', 'score': None, 'meta': {'name': 'fichier_8.txt'}, 'embedding': None, 'id': '1179a409d3e6aa89621b4cd79c16960c'}>, <Document: {'content': \"L'intelligence artificielle exploite les ordinateurs et les machines pour imiter les fonctions de résolution de problèmes et de prise de décision du cerveau humain.\\nQu'est-ce que l'intelligence artificielle ?\\nAlors qu'un certain nombre de définitions de l'intelligence artificielle (IA) ont été proposées au cours des dernières décennies, John McCarthy avance la définition suivante \\ndans cet article de 2004: « C'est la science et l'ingénierie de la fabrication de machines intelligentes, en particulier de programmes informatiques intelligents. \\nElle est liée à la tâche similaire qui consiste à utiliser des ordinateurs pour comprendre l'intelligence humaine, mais l'IA ne doit pas se limiter aux méthodes qui sont \\nCependant, des décennies avant cette définition, la naissance de la discussion sur l'intelligence artificielle était signalée dans l'ouvrage fondamental d'Alan Turing, \\n« Computing Machinery and intelligence » (PDF, 89,8 ko, lien externe à IBM), publié en 1950. Dans ce document, Alan Turing, souvent considéré comme le « père de l'informatique\\n », pose la question suivante : « Les machines peuvent-elles penser ? ». « À partir de là, il propose un test désormais célèbre, appelé « test de Turing », dans lequel un \\ninterrogateur humain tente de distinguer une réponse textuelle d'un ordinateur de celle d'un humain. Bien que ce test ait fait l'objet d'un examen approfondi depuis sa \\npublication, il reste une partie importante de l'histoire de l'IA, ainsi qu'un concept permanent dans la philosophie, car il utilise des idées liées à la linguistique.\\nStuart Russell et Peter Norvig ont publié ensuite Artificial Intelligence: A Modern Approach (lien externe à IBM), devenu l'un des principaux manuels d'étude de l'IA. \\nIls y examinent quatre objectifs ou définitions potentiels de l'IA, qui différencient les systèmes informatiques sur la base de la rationalité et de la réflexion par \\nSystèmes qui pensent comme des êtres humains\\nSystèmes qui agissent comme des êtres humains\\nSystèmes qui pensent rationnellement\\nSystèmes qui agissent rationnellement\\nLa définition d'Alan Turing aurait été classée dans la catégorie des « systèmes qui agissent comme des être humains ».\\nDans sa forme la plus simple, l'intelligence artificielle est un domaine qui combine l'informatique et des ensembles de données solides pour permettre la résolution de \\nproblèmes. Elle englobe également les sous-domaines de l'apprentissage automatique et de l'apprentissage en profondeur qui sont fréquemment mentionnés en association à \\nl'intelligence artificielle. Ces disciplines sont composées d'algorithmes d'IA qui cherchent à créer des systèmes experts qui exécutent des prévisions ou des classifications\\n sur la base de données d'entrée.\\nAujourd'hui, le développement de l'IA fait encore l'objet d'un grand battage médiatique, ce qui est normal pour toute nouvelle technologie émergente sur le marché. Comme le \\nsouligne le cycle du « hype » de Gartner (lien externe à IBM), les innovations de produits telles que les voitures autonomes et les assistants personnels suivent \\n« une progression typique de l'innovation, allant d'un enthousiasme excessif à une période de désillusion, pour finalement comprendre la pertinence et le rôle de l'innovation\\n sur un marché ou dans un domaine ». Comme Lex Fridman le note ici (lien externe à IBM) dans sa conférence au MIT en 2019, nous sommes au sommet des attentes exagérées et nous approchons du creux de la désillusion.\\nAlors que des discussions émergent autour de l'éthique de l'IA, nous pouvons commencer à entrevoir les premiers signes du creux de la désillusion. Pour en savoir plus sur la position d'IBM dans le débat sur l'éthique de l'IA, cliquez ici.\\nTypes d'intelligences artificielles : IA faible versus IA forte\\nL'IA faible, également appelée IA étroite ou intelligence artificielle étroite (ANI, Artificial Narrow Intelligence), est une IA entraînée et concentrée pour effectuer des tâches spécifiques. L'IA faible est en grande partie à l'origine de l'IA qui nous entoure aujourd'hui. Le terme « étroit » serait peut-être plus approprié pour décrire ce type d'IA, car il est tout sauf faible : il se retrouve dans des applications très robustes, comme Siri d'Apple, Alexa d'Amazon, IBM Watson et les véhicules autonomes.\\nL'IA forte se compose de l'intelligence artificielle générale (IAG) et de la super intelligence artificielle (SIA). L'intelligence artificielle générale (IAG), ou IA générale, est une forme théorique d'IA dans laquelle une machine aurait une intelligence égale à celle des êtres humains : elle aurait une conscience d'elle-même, serait capable de résoudre des problèmes, d'apprendre et de planifier l'avenir. La super intelligence artificielle (SIA), également appelée super intelligence, dépasserait l'intelligence et les capacités du cerveau humain. Bien que l'IA forte soit encore entièrement théorique et qu'aucun exemple pratique ne soit utilisé aujourd'hui, cela ne signifie pas que les chercheurs en IA n'explorent pas son développement. En attendant, les meilleurs exemples d'IAG sont peut-être issus de la science-fiction, comme HAL, l'assistant informatique surhumain et dévoyé de 2001 : L'Odyssée de l'espace.\\nApprentissage en profondeur versus Apprentissage automatique\\nLes termes « apprentissage en profondeur » et « apprentissage automatique » ayant tendance à être utilisés indifféremment, il convient de noter les nuances entre les deux. \\nComme mentionné précédemment, l'apprentissage en profondeur et l'apprentissage automatique sont tous les deux des sous-domaines de l'intelligence artificielle, l'apprentissage\\n en profondeur étant en fait un sous-domaine de l'apprentissage automatique.\\nL'apprentissage en profondeur est constitué de réseaux de neurones. Le terme « en profondeur » dans l'expression « apprentissage en profondeur » fait référence à un réseau de neurones composé de plus de trois couches (incluant les entrées et la sortie), et peut être considéré comme un algorithme d'apprentissage en profondeur.\\nLa différence entre l'apprentissage en profondeur et l'apprentissage automatique réside dans la manière dont chaque algorithme apprend. L'apprentissage en profondeur automatise une grande partie de l'extraction des caractéristiques du processus, éliminant une partie de l'intervention humaine manuelle requise et permettant l'utilisation de plus grands ensembles de données. L'apprentissage en profondeur s'apparente à un « apprentissage automatique évolutif », comme l'a noté Lex Fridman dans la même conférence du MIT mentionnée ci-dessus. L'apprentissage automatique classique, ou « non profond », dépend davantage de l'intervention humaine pour apprendre. Les experts humains déterminent la hiérarchie des caractéristiques pour comprendre les différences entre les entrées de données, ce qui nécessite généralement des données plus structurées pour apprendre.\\nL'apprentissage machine « en profondeur » peut s'appuyer sur des ensembles de données étiquetées, on parle également d'apprentissage supervisé, pour informer son algorithme, \\nmais il ne nécessite pas nécessairement un ensemble de données étiquetées. Il peut ingérer des données non structurées dans leur forme brute (texte, images, etc.) et \\ndéterminer automatiquement la hiérarchie des caractéristiques qui distinguent les différentes catégories de données les unes des autres. Contrairement à l'apprentissage \\nautomatique, il ne nécessite pas d'intervention humaine pour traiter les données, ce qui nous permet de faire évoluer l'apprentissage automatique de manière plus intéressante.\\nApplications d'intelligence artificielle\\nLes applications de systèmes d'IA dans le monde réel sont nombreuses aujourd'hui. Voici quelques-uns des exemples d'application les plus courants :\\nReconnaissance vocale : Également appelée « reconnaissance automatique de la parole », « reconnaissance vocale par ordinateur » ou « synthèse vocale », c'est une fonctionnalité qui utilise le traitement du langage naturel (NLP) pour convertir la parole humaine dans un format écrit. Une multitude d'appareils mobiles intègrent la reconnaissance vocale à leurs systèmes pour effectuer des recherches vocales, par exemple, Siri, ou pour fournir une plus grande accessibilité au texte.\\nCentre de support : Les assistants conversationnels en ligne remplacent les agents humains tout au long du parcours du client. Ils répondent aux questions fréquemment posées sur des sujets tels que l'expédition, ou fournissent des conseils personnalisés, proposent des produits de vente croisée ou font des suggestions de taille pour les utilisateurs, changeant ainsi notre façon de concevoir l'engagement des clients sur les sites Web et les plateformes de médias sociaux. Les bots de messagerie sur les sites de commerce électronique avec des agents virtuels, les applications de messagerie, comme Slack et Facebook Messenger, et les tâches habituellement effectuées par les assistants virtuels et les assistants vocaux en sont des exemples.\\nVision par ordinateur : Cette technologie d'IA permet aux ordinateurs et aux systèmes de déduire des informations significatives à partir d'images numériques, de vidéos et autres données visuelles, et d'agir en fonction de ces données. Cette capacité à fournir des recommandations la distingue des tâches de reconnaissance d'image. Optimisée par des réseaux de neurones convolutifs, la vision par ordinateur trouve des applications dans le marquage des photos sur les médias sociaux, l'imagerie radiologique dans les soins de santé et les voitures à conduite autonome dans l'industrie automobile.\\nMoteurs de recommandation : En utilisant des données sur les comportements de consommation passés, les algorithmes d'IA peuvent découvrir des tendances de données qui peuvent être utilisées pour développer des stratégies de vente croisée plus efficaces. Les enseignes en ligne s'en servent pour faire des recommandations pertinentes de produits complémentaires aux clients lors du processus de règlement.\\nNégociation boursière automatisée : Destinées à optimiser les portefeuilles d'actions, les plateformes de négociation haute fréquence optimisées par l'IA effectuent des milliers, voire des millions de transactions par jour sans intervention humaine.\\nHistoire de l'intelligence artificielle : Dates et noms clés\\nL'idée d'une « machine qui pense » remonte à la Grèce antique. Mais depuis l'avènement du calcul électronique (et par rapport à certains des sujets abordés dans cet article), voici quelques événements et étapes importants dans l'évolution de l'intelligence artificielle :\\n1950 : Alan Turing publie Computing Machinery and Intelligence (les machines à calculer et l'intelligence). Dans ce article, Turing, célèbre pour avoir déchiffré le code ENIGMA des Nazis pendant la Seconde Guerre mondiale, propose de répondre à la question « Les machines peuvent-elles penser ? » et introduit le test de Turing pour déterminer si un ordinateur peut faire preuve de la même intelligence (ou obtenir des résultats de même intelligence) qu'un être humain. La valeur du test de Turing fait l'objet d'un débat depuis.\\n1956 : John McCarthy invente le terme « intelligence artificielle » lors de la toute première conférence sur l'IA au Dartmouth College. (McCarthy inventera plus tard le langage Lisp.) Plus tard cette même année, Allen Newell, J.C. Shaw et Herbert Simon créent le Logic Theorist, tout premier logiciel d'IA fonctionnel.\\n1967 : Frank Rosenblatt crée le Perceptron Mark 1, premier ordinateur basé sur un réseau de neurones qui « apprend » par essais et erreurs. Un an plus tard, Marvin Minsky et Seymour Papert publient le livre intitulé Perceptrons, qui devient à la fois l'ouvrage de référence sur les réseaux de neurones et, du moins pendant un certain temps, un argument contre les futurs projets de recherche sur les réseaux de neurones.\\nAnnées 80 : Les réseaux de neurones qui utilisent un algorithme de rétropropagation pour s'entraîner sont largement utilisés dans les applications d'IA.\\n1997 : Lors d'une partie d'échecs (avec revanche), Deep Blue d'IBM bat le champion du monde de l'époque, Garry Kasparov.\\n2011 : IBM Watson bat les champions Ken Jennings et Brad Rutter à Jeopardy!\\n2015 : Le superordinateur Minwa de Baidu utilise un type particulier de réseau de neurones profonds, appelé réseau de neurones convolutifs, pour identifier et classer des images avec un taux de précision supérieur à celui de l'être humain moyen.\\n2016 : Le programme AlphaGo de DeepMind, optimisé par un réseau de neurones profonds, bat Lee Sodol, champion du monde de Go, dans une partie en cinq manches. Cette victoire est importante compte tenu du nombre considérable de coups possibles au cours de la partie (plus de 14 500 milliards après seulement quatre coups !). Plus tard, Google achètera DeepMind pour un montant de 400 millions de dollars.\\nIntelligence artificielle et IBM Cloud\\nIBM a été leader dans le développement des technologies basées sur l'IA pour les entreprises et a ouvert la voie au développement des systèmes d'apprentissage automatique pour de nombreux secteurs. En s'appuyant sur des décennies de recherche sur l'intelligence artificielle, sur des années d'expérience avec des organisations de toutes tailles et sur les enseignements tirés de plus de 30 000 engagements IBM Watson, IBM a développé l'approche AI Ladder pour mener à bien les déploiements d'intelligence artificielle :\\nCollecter : Simplification de la collecte des données et de leur accessibilité.\\nOrganiser : Création d'une base d'analyse prête à l'emploi.\\nAnalyser : Création de systèmes gérés par IA évolutifs et fiables.\\nInfuser : Intégration et optimisation de systèmes dans l'ensemble d'une infrastructure métier.\\nModerniser : Transfert de vos applications et de vos systèmes d'intelligence artificielle vers le cloud.\", 'content_type': 'text', 'score': None, 'meta': {'name': 'fichier_2.txt'}, 'embedding': None, 'id': '9ff8f1535256ba93ac5d11b73b0ed2a4'}>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever = BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "j75uSmjaqww4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = FARMReader(model_name_or_path=\"etalab-ia/camembert-base-squadFR-fquad-piaf\", use_gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "52e781efaa004e87b88cc13f9b89bed3",
            "9992a73b9b2f4c3db1697b981ed6cd50",
            "5650adb8624f43dd8ddd3dd62626adbc",
            "1d11b738197e4a408f1aac8434dcc343",
            "4115e57fd25e43bc9dfe7a4129bf6ccd",
            "89449c49276f437e910f6ef4cc084634",
            "01c21f089f524656bb0d2e979efc6ce6",
            "cea3d63391d0403f97889ea0b5a0b2e0",
            "46a77b393303454baedb7760710d677a",
            "1673edea5f914a85a1236c7895e3b3f4",
            "db27a5882fba48fd90ea585f2f385c15",
            "2ccab23d79564088be976c3b202935aa",
            "244ca366a0a74cc59eaaf2c9b3e14b12",
            "54c4cfac032244489ac0945c0657db02",
            "6eaf4cece883445c97f47564197c067f",
            "d76c2c6ee78142f88958228d2034e51f",
            "a66924a9734d4bbab8aeb1c03b913f84",
            "1de9c11a77524c25858a8d750ed22cb8",
            "dd6483728a854bbf894a73fca9a38fb3",
            "2a23e3c1eac84fd19d4e742511c740a2",
            "e339d7ec554b4ced898f6fcb5fa43266",
            "25a3aacc7f9046c98282dd6312b87909",
            "f4d0062a9c1045719c487e1505b29688",
            "506dbb6525ad498eaae16fc3888ccd8d",
            "e4004111d9a14698981dd717c576bca8",
            "668f34c8e68349dda6e12c16e6ea09bc",
            "9416c6bea486422a82ca76eb0cba6646",
            "c9537b7a64c747b693d582525ff00446",
            "8342180b43454a29bafc98d615afe130",
            "fcd898c7f67e489b82070fd2c4a93d46",
            "961d4042fc7f490e8baed99fbaecfda4",
            "66bc14c4048f4c61837e60273f7ce9a7",
            "20e8819deead42f78f246f1a19c981f1",
            "d3c4815269be42b3afbd8007212db9cb",
            "03c7c650ded24e0d898d6844ebf25b1e",
            "748114b72a6f44beacef1a8dc04f73d9",
            "7782c84750ea4834aeb9d0854714e120",
            "5172822f6cc241bea2221f739b4440bf",
            "2e89cf040b634c41af45bf813a8c299f",
            "97045a243dd74c44bcec0ce6ee6ed8f0",
            "28ddf69596254504bb199d30c7bb61ae",
            "2cc123b1c9e345b0b3e6825efc850609",
            "cfa27427b9a84feba3b229741b335029",
            "44df1829dc5b4cc4a77ff47a5a91c24b",
            "f60626d9535e4a9093370418e0e4c2b7",
            "7225d02ee71b4d10b7ba667476a4bd8b",
            "bc37c295fbe445bdb78e8ef92c610367",
            "c604c9f8790942fd80d5755c3ada8913",
            "ef2b864dc372472d9d5718d4c751da05",
            "a550b9d39acc40da972a937cae93a74d",
            "777c68e7b3f04ed2b526b2be34251a7c",
            "dd8667cea1494be8b199d1bd72e6acae",
            "906c23c58119416f9e201846fb2c4a35",
            "66cd48aff19243aa9924a4fe5fd06037",
            "736fffeb753844f3952e8cb0b31731ff"
          ]
        },
        "id": "Mi_PBxD-q-Eh",
        "outputId": "b0ee6b3f-3551-41b7-ddf8-14d45696f18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/515 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52e781efaa004e87b88cc13f9b89bed3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'etalab-ia/camembert-base-squadFR-fquad-piaf' (Camembert)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ccab23d79564088be976c3b202935aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: french\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'etalab-ia/camembert-base-squadFR-fquad-piaf' (Camembert model) from model hub.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4d0062a9c1045719c487e1505b29688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3c4815269be42b3afbd8007212db9cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f60626d9535e4a9093370418e0e4c2b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "metadata": {
        "id": "sA5zbbPArMXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question=\"What is artificial intelligence?\""
      ],
      "metadata": {
        "id": "FC7PjfleshfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gVG_gjIk4r1",
        "outputId": "f959b86c-0c70-467e-ee76-dea3ef2b564e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "GIyM4WhGlEoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "DeQIQ5y2lJZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des mots vides en français\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"french\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83RITgC8lM7N",
        "outputId": "20021527-c3f5-44a6-ed00-0e2c31134e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour supprimer les mots vides\n",
        "def remove_stop_words(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return \" \".join(filtered_words)"
      ],
      "metadata": {
        "id": "OiMrGG4edoIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Texte à traiter\n",
        "question=\"C'est quoi l'intelligence artificielle?\""
      ],
      "metadata": {
        "id": "iHk8Bc-MdrJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer les mots vides\n",
        "filtered_question = remove_stop_words(question)\n",
        "\n",
        "print(filtered_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmwvRoA6dt3p",
        "outputId": "8f53ad72-0976-432f-f370-63306a8f9a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C'est quoi l'intelligence artificielle?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can configure how many candidates the Reader and Retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(\n",
        "    query=filtered_question, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d8466665e08e4c55ad16239e265574b3",
            "c12b196da2844d0a89bb333be851ef5e",
            "9a7b315ba0494798907e1aa1fe4d4151",
            "21bfe64b40594407973415f23f29531e",
            "94c1395194f840adae51463734c95e49",
            "f43028f6d57c4ec0bbbb9600a5908aa5",
            "c2c33555b1254e4ba0637c153604dc02",
            "2ba89333024045a2bd862487851109d1",
            "0536e1e083d94f8fb0b74f3771a60fd9",
            "688a3b06bcb349fba1fd44769a31c27a",
            "6a49164acd2b4611a85f8bbf6923f022"
          ]
        },
        "id": "-Ue0FGhLsyX3",
        "outputId": "4acd2eab-479c-4eb0-8942-9d6e7e479b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Inferencing Samples:   0%|          | 0/4 [00:00<?, ? Batches/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8466665e08e4c55ad16239e265574b3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "pipeline = DocumentSearchPipeline(retriever)\n",
        "query1 = 'est  intelligence artificielle? '\n",
        "resultt = pipeline.run(query1, params={\"Retriever\": {\"top_k\": 10}})"
      ],
      "metadata": {
        "id": "g8NgYY8xVtCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import print_documents\n",
        "\n",
        "print_documents(resultt, max_text_len=100, print_name=True, print_meta=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54zKCLOYV9Ps",
        "outputId": "b1274289-31d7-4f63-d750-f75bec9c7358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: est  intelligence artificielle? \n",
            "\n",
            "{   'content': 'ChatGPT, Midjourney… les IA sont plus que jamais dans '\n",
            "               'l’actualité. Mais, quelle est la définition d’...',\n",
            "    'meta': {'name': 'fichier_5.txt'},\n",
            "    'name': 'fichier_5.txt'}\n",
            "\n",
            "{   'content': \"L'intelligence artificielle exploite les ordinateurs et les \"\n",
            "               'machines pour imiter les fonctions de ré...',\n",
            "    'meta': {'name': 'fichier_2.txt'},\n",
            "    'name': 'fichier_2.txt'}\n",
            "\n",
            "{   'content': \"L'intelligence artificielle (IA) est un « ensemble de théories \"\n",
            "               'et de techniques mises en œuvre en vu...',\n",
            "    'meta': {'name': 'fichier_1.txt'},\n",
            "    'name': 'fichier_1.txt'}\n",
            "\n",
            "{   'content': \"Définition de l'intelligence artificielle : L'intelligence \"\n",
            "               'artificielle (IA, ou AI en anglais pour A...',\n",
            "    'meta': {'name': 'fichier_4.txt'},\n",
            "    'name': 'fichier_4.txt'}\n",
            "\n",
            "{   'content': 'Traduction automatique, reconnaissance d’image, reconnaissance '\n",
            "               'faciale, assistants vocaux, chatbots,...',\n",
            "    'meta': {'name': 'fichier_3.txt'},\n",
            "    'name': 'fichier_3.txt'}\n",
            "\n",
            "{   'content': \"Stratégie nationale pour l'intelligence artificielle\\n\"\n",
            "               \"Stratégie nationale pour l'intelligence artific...\",\n",
            "    'meta': {'name': 'fichier_7.txt'},\n",
            "    'name': 'fichier_7.txt'}\n",
            "\n",
            "{   'content': \"Le développement et l'utilisation de l'IA sont aujourd'hui un \"\n",
            "               \"sujet d'actualité. Les experts et les ...\",\n",
            "    'meta': {'name': 'fichier_6.txt'},\n",
            "    'name': 'fichier_6.txt'}\n",
            "\n",
            "{   'content': 'Intelligence artificielle et diagnostic médical : des '\n",
            "               'bienfaits mais à manier prudemment\\n'\n",
            "               '\"Les équipe...',\n",
            "    'meta': {'name': 'fichier_10.txt'},\n",
            "    'name': 'fichier_10.txt'}\n",
            "\n",
            "{   'content': 'L’intelligence artificielle, ou IA, est entrain de changer le '\n",
            "               'monde. Du domaine bancaire à l’entrepr...',\n",
            "    'meta': {'name': 'fichier_8.txt'},\n",
            "    'name': 'fichier_8.txt'}\n",
            "\n",
            "{   'content': 'Le domaine de la médecine s’est fortement modernisé en '\n",
            "               'profitant des différentes révolutions industr...',\n",
            "    'meta': {'name': 'fichier_9.txt'},\n",
            "    'name': 'fichier_9.txt'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction['answers'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22SodYhreOJ",
        "outputId": "80fe1012-b7ec-43e8-b7d9-1142e9a6d609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Answer {'answer': 'IBM Cloud', 'type': 'extractive', 'score': 0.9873433113098145, 'context': \"ur un montant de 400 millions de dollars.\\nIntelligence artificielle et IBM Cloud\\nIBM a été leader dans le développement des technologies basées sur l'\", 'offsets_in_document': [{'start': 12868, 'end': 12877}], 'offsets_in_context': [{'start': 71, 'end': 80}], 'document_id': '9ff8f1535256ba93ac5d11b73b0ed2a4', 'meta': {'name': 'fichier_2.txt'}}>,\n",
            " <Answer {'answer': '(IA),', 'type': 'extractive', 'score': 0.9426077008247375, 'context': 'ergence de l’internet des objets (IoT) et de l’intelligence artificielle (IA), offrent maintenant aux patients la possibilité d’introduire des solutio', 'offsets_in_document': [{'start': 574, 'end': 579}], 'offsets_in_context': [{'start': 73, 'end': 78}], 'document_id': '9f3c3ec923144d93721e2165b835162d', 'meta': {'name': 'fichier_9.txt'}}>,\n",
            " <Answer {'answer': 'GPT-3.5', 'type': 'extractive', 'score': 0.907520592212677, 'context': 'sible de supprimer vos données).\\nCe chatbot est en réalité un dérivé de GPT-3.5, intelligence artificielle conçue pour générer du texte le plus nature', 'offsets_in_document': [{'start': 5941, 'end': 5948}], 'offsets_in_context': [{'start': 72, 'end': 79}], 'document_id': '67af0c8c2f82b1aedb16d66ecfdacfcf', 'meta': {'name': 'fichier_5.txt'}}>,\n",
            " <Answer {'answer': 'signification', 'type': 'extractive', 'score': 0.8890624046325684, 'context': \" sensb n'est pas toujours formalisé, ce qui ramène au problème de la signification en intelligence artificielle, et de la subjectivité des utilisateur\", 'offsets_in_document': [{'start': 13599, 'end': 13612}], 'offsets_in_context': [{'start': 69, 'end': 82}], 'document_id': 'a382903def5476bea85f32933e3f6ac0', 'meta': {'name': 'fichier_1.txt'}}>,\n",
            " <Answer {'answer': 'Les machines qui se limitent à résoudre des problèmes', 'type': 'extractive', 'score': 0.871062159538269, 'context': \"e des sentiments éprouvés par les êtres humains. Les machines qui se limitent à résoudre des problèmes entrent dans la catégorie d'intelligence artifi\", 'offsets_in_document': [{'start': 4003, 'end': 4056}], 'offsets_in_context': [{'start': 49, 'end': 102}], 'document_id': '922fde6836366a0663aba19317a77b4d', 'meta': {'name': 'fichier_4.txt'}}>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "pipeline = DocumentSearchPipeline(retriever)\n",
        "query = 'c est quoi l intelligence artificielle? '\n",
        "result = pipeline.run(query, params={\"Retriever\": {\"top_k\": 10}})\n"
      ],
      "metadata": {
        "id": "WC1fC2z1rmgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import print_documents\n",
        "\n",
        "print_documents(result, max_text_len=100, print_name=True, print_meta=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiWVMn6ctMXi",
        "outputId": "900fde2b-5996-4f36-9af2-2fc4b3080c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: c est quoi l intelligence artificielle? \n",
            "\n",
            "{   'content': 'ChatGPT, Midjourney… les IA sont plus que jamais dans '\n",
            "               'l’actualité. Mais, quelle est la définition d’...',\n",
            "    'meta': {'name': 'fichier_5.txt'},\n",
            "    'name': 'fichier_5.txt'}\n",
            "\n",
            "{   'content': \"Définition de l'intelligence artificielle : L'intelligence \"\n",
            "               'artificielle (IA, ou AI en anglais pour A...',\n",
            "    'meta': {'name': 'fichier_4.txt'},\n",
            "    'name': 'fichier_4.txt'}\n",
            "\n",
            "{   'content': \"L'intelligence artificielle (IA) est un « ensemble de théories \"\n",
            "               'et de techniques mises en œuvre en vu...',\n",
            "    'meta': {'name': 'fichier_1.txt'},\n",
            "    'name': 'fichier_1.txt'}\n",
            "\n",
            "{   'content': \"L'intelligence artificielle exploite les ordinateurs et les \"\n",
            "               'machines pour imiter les fonctions de ré...',\n",
            "    'meta': {'name': 'fichier_2.txt'},\n",
            "    'name': 'fichier_2.txt'}\n",
            "\n",
            "{   'content': 'Traduction automatique, reconnaissance d’image, reconnaissance '\n",
            "               'faciale, assistants vocaux, chatbots,...',\n",
            "    'meta': {'name': 'fichier_3.txt'},\n",
            "    'name': 'fichier_3.txt'}\n",
            "\n",
            "{   'content': \"Stratégie nationale pour l'intelligence artificielle\\n\"\n",
            "               \"Stratégie nationale pour l'intelligence artific...\",\n",
            "    'meta': {'name': 'fichier_7.txt'},\n",
            "    'name': 'fichier_7.txt'}\n",
            "\n",
            "{   'content': \"Le développement et l'utilisation de l'IA sont aujourd'hui un \"\n",
            "               \"sujet d'actualité. Les experts et les ...\",\n",
            "    'meta': {'name': 'fichier_6.txt'},\n",
            "    'name': 'fichier_6.txt'}\n",
            "\n",
            "{   'content': 'Intelligence artificielle et diagnostic médical : des '\n",
            "               'bienfaits mais à manier prudemment\\n'\n",
            "               '\"Les équipe...',\n",
            "    'meta': {'name': 'fichier_10.txt'},\n",
            "    'name': 'fichier_10.txt'}\n",
            "\n",
            "{   'content': 'L’intelligence artificielle, ou IA, est entrain de changer le '\n",
            "               'monde. Du domaine bancaire à l’entrepr...',\n",
            "    'meta': {'name': 'fichier_8.txt'},\n",
            "    'name': 'fichier_8.txt'}\n",
            "\n",
            "{   'content': 'Le domaine de la médecine s’est fortement modernisé en '\n",
            "               'profitant des différentes révolutions industr...',\n",
            "    'meta': {'name': 'fichier_9.txt'},\n",
            "    'name': 'fichier_9.txt'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9neFYaCh2oM",
        "outputId": "85938d61-98a4-4f09-bd95-b62e7a7e7de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Program to measure the similarity between\n",
        "# two sentences using cosine similarity.\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# X = input(\"Enter first string: \").lower()\n",
        "# Y = input(\"Enter second string: \").lower()\n",
        "X =result1\n",
        "Y =result\n",
        "\n",
        "# tokenization\n",
        "X_list = word_tokenize(X)\n",
        "Y_list = word_tokenize(Y)\n",
        "\n",
        "# sw contains the list of stopwords\n",
        "sw = stopwords.words('french')\n",
        "l1 =[];l2 =[]\n",
        "\n",
        "# remove stop words from the string\n",
        "X_set = {w for w in X_list if not w in sw}\n",
        "Y_set = {w for w in Y_list if not w in sw}\n",
        "\n",
        "# form a set containing keywords of both strings\n",
        "rvector = X_set.union(Y_set)\n",
        "for w in rvector:\n",
        "\tif w in X_set: l1.append(1) # create a vector\n",
        "\telse: l1.append(0)\n",
        "\tif w in Y_set: l2.append(1)\n",
        "\telse: l2.append(0)\n",
        "c = 0\n",
        "\n",
        "# cosine formula\n",
        "for i in range(len(rvector)):\n",
        "\t\tc+= l1[i]*l2[i]\n",
        "cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "print(\"similarity: \", cosine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "PMXvP8-7hkl8",
        "outputId": "f46b3e26-3141-4c8d-bd2a-0b485a87cb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-434af6a31db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mY_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \"\"\"\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \"\"\"\n\u001b[1;32m   1420\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0mbefore_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;31m# Ignore matches that have already been captured by matches to the right of this match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbefore_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x.to_dict() for x in result[\"documents\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaNq58GKuUOa",
        "outputId": "5b0a4274-6c07-472f-f74d-269a33bc32e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': \"Artificial intelligence (AI) is a wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence. AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry. \\nArtificial intelligence allows machines to model, and even improve upon, the capabilities of the human mind. \\nFrom the development of self-driving cars to the proliferation of smart assistants like Siri and Alexa, AI is a growing part of everyday life. As a result, many tech companies across various industries are investing in artificially intelligent technologies.\\nLess than a decade after helping the Allied forces win World War II by breaking the Nazi encryption machine Enigma, mathematician Alan Turing changed history a second time with a simple question: “Can machines think?” \\nTuring’s 1950 paper “Computing Machinery and Intelligence” and its subsequent Turing Test established the fundamental goal and vision of AI.   \\nAt its core, AI is the branch of computer science that aims to answer Turing’s question in the affirmative. It is the endeavor to replicate or simulate human intelligence in machines. The expansive goal of AI has given rise to many questions and debates. So much so that no singular definition of the field is universally accepted.\\nThe major limitation in defining AI as simply “building machines that are intelligent” is that it doesn't actually explain what AI is and what makes a machine intelligent. AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry.\\nHowever, various new tests have been proposed recently that have been largely well received, including a 2019 research paper entitled “On the Measure of Intelligence.” In the paper, veteran deep learning researcher and Google engineer François Chollet argues that intelligence is the “rate at which a learner turns its experience and priors into new skills at valuable tasks that involve uncertainty and adaptation.” In other words: The most intelligent systems are able to take just a small amount of experience and go on to guess what would be the outcome in many varied situations.\\nMeanwhile, in their book Artificial Intelligence: A Modern Approach, authors Stuart Russell and Peter Norvig approach the concept of AI by unifying their work around the theme of intelligent agents in machines. With this in mind, AI is “the study of agents that receive percepts from the environment and perform actions.”\",\n",
              "  'content_type': 'text',\n",
              "  'score': 0.511475598160794,\n",
              "  'meta': {'name': 'AI.txt'},\n",
              "  'embedding': None,\n",
              "  'id': '15b3f9b9900b37443010984e28441d30'},\n",
              " {'content': 'Since the invention of computers or machines, their capability to perform various tasks went\\non growing exponentially. Humans have developed the power of computer systems in terms\\nof their diverse working domains, their increasing speed, and reducing size with respect to\\nA branch of Computer Science named Artificial Intelligence pursues creating the computers or\\nmachines as intelligent as human beings.\\nAccording to the father of Artificial Intelligence John McCarthy, it is “The science and\\nengineering of making intelligent machines, especially intelligent computer programs”.\\nArtificial Intelligence is a way of making a computer, a computer-controlled robot, or a\\nsoftware think intelligently, in the similar manner the intelligent humans think.\\nAI is accomplished by studying how human brain thinks, and how humans learn, decide, and\\nwork while trying to solve a problem, and then using the outcomes of this study as a basis of\\ndeveloping intelligent software and systems.\\nArtificial intelligence is a science and technology based on disciplines such as Computer\\nScience, Biology, Psychology, Linguistics, Mathematics, and Engineering. A major thrust of AI\\nis in the development of computer functions associated with human intelligence, such as\\nreasoning, learning, and problem solving.\\nOut of the following areas, one or multiple areas can contribute to build an intelligent system.\\nIn the real world, the knowledge has some unwelcomed properties:\\n\\uf0b7 Its volume is huge, next to unimaginable.\\n\\uf0b7 It is not well-organized or well-formatted.\\n\\uf0b7 It keeps changing constantly.\\nAI Technique is a manner to organize and use the knowledge efficiently in such a way that:\\n\\uf0b7 It should be perceivable by the people who provide it.\\n\\uf0b7 It should be easily modifiable to correct errors.\\n\\uf0b7 It should be useful in many situations though it is incomplete or inaccurate.\\nAI techniques elevate the speed of execution of the complex program it is equipped with.\\nLearning: It is the activity of gaining knowledge or skill by studying, practising, being\\ntaught, or experiencing something. Learning enhances the awareness of the subjects\\n The ability of learning is possessed by humans, some animals, and AI-enabled\\nsystems. Learning is categorized as:\\no Auditory Learning: It is learning by listening and hearing. For example, students\\nlistening to recorded audio lectures.\\no Episodic Learning: To learn by remembering sequences of events that one has\\nwitnessed or experienced. This is linear and orderly.\\no Motor Learning: It is learning by precise movement of muscles. For example,\\no Observational Learning: To learn by watching and imitating others. For example,\\nchild tries to learn by mimicking her parent.\\no Perceptual Learning: It is learning to recognize stimuli that one has seen before.\\nFor example, identifying and classifying objects and situations.\\no Relational Learning: It involves learning to differentiate among various stimuli\\non the basis of relational properties, rather than absolute properties. For Example,\\nAdding ‘little less’ salt at the time of cooking potatoes that came up salty last time,\\nwhen cooked with adding say a tablespoon of salt.\\no Spatial learning: It is learning through visual stimuli such as images, colors,\\nmaps, etc. For Example, A person can create roadmap in mind before actually\\no Stimulus-Response Learning: It is learning to perform a particular behavior\\nwhen a certain stimulus is present. For example, a dog raises its ear on hearing\\n3. Problem solving: It is the process in which one perceives and tries to arrive at a\\ndesired solution from a present situation by taking some path, which is blocked by\\nProblem solving also includes decision making, which is the process of selecting the\\nbest suitable alternative out of multiple alternatives to reach the desired goal are\\n4. Perception: It is the process of acquiring, interpreting, selecting, and organizing',\n",
              "  'content_type': 'text',\n",
              "  'score': 0.5098707517756995,\n",
              "  'meta': {'name': 'fichier-test.txt'},\n",
              "  'embedding': None,\n",
              "  'id': '164f60f58182a00a9f3c44c7126e9f71'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5uyEwZSud6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}