{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e50c7784323d4ad8b9c9447f43f8bb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b09d5bfe81f34e8a9487c050d50ab893",
              "IPY_MODEL_2ebd64ea1bbd4ad1b5021a6d96e1bbd1",
              "IPY_MODEL_320ab5ae2f354f81a3ee13087d24307f"
            ],
            "layout": "IPY_MODEL_7fa0656eca2c49ff953e0a9d9fe87d6a"
          }
        },
        "b09d5bfe81f34e8a9487c050d50ab893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c91c55b2fcb4cd98e5123bea3caeb8d",
            "placeholder": "​",
            "style": "IPY_MODEL_49f0cdc0921d4dabb0d1bf7425b803f9",
            "value": "Inferencing Samples: 100%"
          }
        },
        "2ebd64ea1bbd4ad1b5021a6d96e1bbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21e8757baa14f06bc2871bffdd1e700",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a26b3ccab3d345c3b0f5fa9131da3286",
            "value": 1
          }
        },
        "320ab5ae2f354f81a3ee13087d24307f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c991cb6e23974210a354f02c35aeb889",
            "placeholder": "​",
            "style": "IPY_MODEL_9e151923dcb9412ca02c2a680c988073",
            "value": " 1/1 [00:05&lt;00:00,  5.77s/ Batches]"
          }
        },
        "7fa0656eca2c49ff953e0a9d9fe87d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c91c55b2fcb4cd98e5123bea3caeb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f0cdc0921d4dabb0d1bf7425b803f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b21e8757baa14f06bc2871bffdd1e700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26b3ccab3d345c3b0f5fa9131da3286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c991cb6e23974210a354f02c35aeb889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e151923dcb9412ca02c2a680c988073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/MIMICData"
      ],
      "metadata": {
        "id": "BeboKMBRjk1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/datafr.zip -d /content/MIMICData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnh9gG0Xkn_Z",
        "outputId": "f91d064b-8396-4f82-baaa-937cb2ecbb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/datafr.zip\n",
            "  inflating: /content/MIMICData/datafr/AI.txt  \n",
            "  inflating: /content/MIMICData/datafr/textAI.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/MIMICData/datafr/textAI.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjF1O-0uvb3A",
        "outputId": "02d92d6c-9d76-49e4-a60b-b5fb641099c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On utilise le terme �d�intelligence artificielle� ou d�IA pour d�signer les ordinateurs et programmes informatiques capables de performances habituellement associ�es � l�intelligence humaine. Par exemple, la capacit� � interagir avec l�homme, � traiter de grandes quantit�s de donn�es ou encore � apprendre progressivement et donc � s�am�liorer de mani�re continue. C�est donc un vaste sujet, en perp�tuelle �volution !\r\n",
            "L�intelligence artificielle peut se d�finir comme � l�ensemble de th�ories et de techniques mises en �uvre en vue de r�aliser des machines capables de simuler l�intelligence �, selon le Larousse. Soit des ordinateurs ou des programmes avec des puissances de calcul capables de performances habituellement associ�es � l�intelligence humaine, et amplifi�es par la technologie : \r\n",
            "- Capacit� de raisonner\r\n",
            "- Capacit� de traiter de grandes quantit�s de donn�es\r\n",
            "- Facult� de discerner des patterns et des mod�les ind�tectables par un humain\r\n",
            "- Aptitude � comprendre et analyser ces mod�les\r\n",
            "- Capacit�s � interagir avec l�homme\r\n",
            "- Facult� d�apprendre progressivement\r\n",
            "- Et d�am�liorer continuellement ses performances\r\n",
            "� L�intelligence artificielle � couvre donc un vaste sujet, en perp�tuel mutation. Et aux progr�s fulgurants depuis 1950, ann�e fondatrice de l�IA.\r\n",
            "\r\n",
            "Webinar \r\n",
            "L�IA et le cloud computing au service de la pratique clinique\r\n",
            "L�IA est amen�e � prendre une place plus importante dans le quotidien des cliniciens : Du patient connect�, aux outils d�aide � la d�cision, quelles seront les tendances � venir du secteur ?\r\n",
            "\r\n",
            "VISIONNER \r\n",
            "L�intelligence artificielle aujourd�hui\r\n",
            "En 2017, l�intelligence artificielle a franchi une �tape d�cisive, parvenant � identifier les mots dans une conversation orale aussi bien qu�un �tre humain, ouvrant de nouvelles perspectives pour la reconnaissance vocale et la traduction automatique dans la vie courante.\r\n",
            "\r\n",
            "Janvier 2018, nouvelle prouesse : l�IA d�passe les humains lors de diff�rents d�exercices de lecture et de compr�hension, dans le c�l�bre test de lecture de l�universit� de Stanford. Cela permettra � l�intelligence artificielle, demain, d�interagir encore plus facilement avec les humains, pour leur apporter de l�information de mani�re plus naturelle.\r\n",
            "\r\n",
            "Une belle promesse, mais aussi une r�alit� tr�s concr�te, r�sum�e dans un sourire par Harry Shum, Executive Vice-President AI & Research de Microsoft : � Bien s�r qu�il faut aimer l�IA ! Apr�s tout, qu�est-ce que l�oppos� de l�intelligence artificielle ? La stupidit� naturelle �.\r\n",
            "\r\n",
            "Harry Shum, Executive Vice President de Microsoft, en charge de l'intelligence artificielle\r\n",
            "Harry Shum, Executive Vice President de Microsoft, en charge de l�intelligence artificielle\r\n",
            "2. Comment fonctionne l�intelligence artificielle ?\r\n",
            "La r�volution actuelle de l�intelligence artificielle et de la science qui en d�coule est rendue possible par � une combinaison de 3 facteurs �. Selon Harry Shum : � une vaste quantit� de data ; une puissance informatique extraordinaire, notamment gr�ce au cloud ; et des algorithmes r�volutionnaires, bas�s sur le deep-learning �.\r\n",
            "\r\n",
            "L�apprentissage supervis�\r\n",
            "L�IA a ainsi fr�quemment recours � l�apprentissage supervis�. Par exemple, on � nourrit � un programme avec des milliers de photos de voitures, �tiquet�es. Apr�s cet � entrainement �, le programme peut reconna�tre, seul, des voitures de tous types sur les nouvelles images qui lui seront pr�sent�es.\r\n",
            "\r\n",
            "Le Machine Learning\r\n",
            "Autre composant de l�intelligence artificielle, le � Machine Learning �. Cette fois, on donne aux ordinateurs l�acc�s � des donn�es, puis on les laisse apprendre par eux-m�mes, sans intervention humaine ou reprogrammation logicielle. Ce qui leur permet de s�am�liorer progressivement, de mani�re autonome. Et de d�passer ainsi les fonctions et les capacit�s initialement programm�es.\r\n",
            "Certains algorithmes ne se contentent plus de reconna�tre des images, mais se montrent capables de les produire et de donner des yeux aux machines."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest release of Haystack in your own environment \n",
        "#! pip install farm-haystack\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIfHt_ppk3aA",
        "outputId": "e4cf43d0-c9bb-4113-c465-8c11f7eccee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farm-haystack[colab]\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-install-br248t69/farm-haystack_7f463f8061924a829d25a90fc46ae774\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-install-br248t69/farm-haystack_7f463f8061924a829d25a90fc46ae774\n",
            "  Resolved https://github.com/deepset-ai/haystack.git to commit 15203d864be9bbe5f39585a9081a940e7101abb5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.3.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (9.0.0)\n",
            "Collecting azure-ai-formrecognizer>=3.2.0b2\n",
            "  Using cached azure_ai_formrecognizer-3.2.0-py3-none-any.whl (228 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.10.4)\n",
            "Collecting posthog\n",
            "  Using cached posthog-2.2.0-py2.py3-none-any.whl (33 kB)\n",
            "Collecting quantulum3\n",
            "  Using cached quantulum3-0.8.0-py3-none-any.whl (10.7 MB)\n",
            "Collecting langdetect\n",
            "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
            "Collecting seqeval\n",
            "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
            "Collecting mlflow\n",
            "  Using cached mlflow-2.1.1-py3-none-any.whl (16.7 MB)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.19.6)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (0.8.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (2.25.1)\n",
            "Collecting huggingface-hub>=0.5.0\n",
            "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (4.64.1)\n",
            "Collecting elasticsearch<8,>=7.7\n",
            "  Using cached elasticsearch-7.17.8-py2.py3-none-any.whl (385 kB)\n",
            "Collecting transformers[torch]==4.25.1\n",
            "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "Collecting sentence-transformers>=2.2.0\n",
            "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.3.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.0)\n",
            "Collecting tika\n",
            "  Using cached tika-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (1.7.3)\n",
            "Collecting rapidfuzz<2.8.0,>=2.0.15\n",
            "  Using cached rapidfuzz-2.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Requirement already satisfied: mmh3 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (3.0.0)\n",
            "Requirement already satisfied: pillow<=9.0.0 in /usr/local/lib/python3.8/dist-packages (from farm-haystack[colab]) (7.1.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (21.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]==4.25.1->farm-haystack[colab]) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (4.4.0)\n",
            "Collecting azure-core<2.0.0,>=1.23.0\n",
            "  Using cached azure_core-1.26.2-py3-none-any.whl (173 kB)\n",
            "Collecting msrest>=0.6.21\n",
            "  Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.8/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (1.1.28)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from elasticsearch<8,>=7.7->farm-haystack[colab]) (1.26.14)\n",
            "Collecting jarowinkler<2.0.0,>=1.2.0\n",
            "  Using cached jarowinkler-1.2.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab]) (0.1.97)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab]) (0.14.1+cu116)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->farm-haystack[colab]) (5.10.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect->farm-haystack[colab]) (1.15.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4)\n",
            "Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2022.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
            "  Using cached importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (3.4.1)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.4.46)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.1.4)\n",
            "Collecting databricks-cli<1,>=0.8.7\n",
            "  Using cached databricks_cli-0.17.4-py3-none-any.whl\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (7.1.2)\n",
            "Collecting alembic<2\n",
            "  Using cached alembic-1.9.1-py3-none-any.whl (210 kB)\n",
            "Collecting docker<7,>=4.0.0\n",
            "  Using cached docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (0.4.3)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.11.3)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Using cached GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (2.2.0)\n",
            "Requirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (9.0.0)\n",
            "Collecting gunicorn<21\n",
            "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.8/dist-packages (from mlflow->farm-haystack[colab]) (1.2.4)\n",
            "Collecting shap<1,>=0.40\n",
            "  Using cached shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.10)\n",
            "Collecting backoff<2.0.0,>=1.10.0\n",
            "  Using cached backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.8/dist-packages (from posthog->farm-haystack[colab]) (1.6)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from python-docx->farm-haystack[colab]) (4.9.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (from quantulum3->farm-haystack[colab]) (2.1.0)\n",
            "Collecting num2words\n",
            "  Using cached num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tika->farm-haystack[colab]) (57.4.0)\n",
            "Collecting Mako\n",
            "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (2.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->farm-haystack[colab]) (0.8.10)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from docker<7,>=4.0.0->mlflow->farm-haystack[colab]) (1.4.2)\n",
            "Collecting requests\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->farm-haystack[colab]) (2.1.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->farm-haystack[colab]) (1.0.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->farm-haystack[colab]) (3.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow->farm-haystack[colab]) (1.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab]) (1.3.1)\n",
            "Collecting isodate>=0.6.0\n",
            "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.56.4)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->farm-haystack[colab]) (2.0.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from num2words->quantulum3->farm-haystack[colab]) (0.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow->farm-haystack[colab]) (5.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow->farm-haystack[colab]) (0.39.1)\n",
            "Building wheels for collected packages: farm-haystack\n",
            "  Building wheel for farm-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.13.0rc0-py3-none-any.whl size=602426 sha256=2198a392c35d3d212aacec5d6bd1b4a4e57790aeef0231941145e762c68d190c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fw2uhmer/wheels/97/0d/ae/77cde17929fbf66c8320f19b30789acfe52e2312bb1d125be1\n",
            "Successfully built farm-haystack\n",
            "Installing collected packages: requests, num2words, Mako, langdetect, jarowinkler, isodate, importlib-metadata, gunicorn, gitdb, elasticsearch, backoff, tika, rapidfuzz, quantulum3, posthog, huggingface-hub, gitpython, docker, databricks-cli, azure-core, alembic, transformers, shap, seqeval, msrest, sentence-transformers, mlflow, azure-ai-formrecognizer, farm-haystack\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.0.0\n",
            "    Uninstalling importlib-metadata-6.0.0:\n",
            "      Successfully uninstalled importlib-metadata-6.0.0\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.1 azure-ai-formrecognizer-3.2.0 azure-core-1.26.2 backoff-1.11.1 databricks-cli-0.17.4 docker-6.0.1 elasticsearch-7.17.8 farm-haystack-1.13.0rc0 gitdb-4.0.10 gitpython-3.1.30 gunicorn-20.1.0 huggingface-hub-0.11.1 importlib-metadata-5.2.0 isodate-0.6.1 jarowinkler-1.2.3 langdetect-1.0.9 mlflow-2.1.1 msrest-0.7.1 num2words-0.5.12 posthog-2.2.0 quantulum3-0.8.0 rapidfuzz-2.7.0 requests-2.28.1 sentence-transformers-2.2.2 seqeval-1.2.2 shap-0.41.0 tika-2.6.0 transformers-4.25.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "OL7bzEY0k62b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http, print_answers\n",
        "from haystack.nodes import FARMReader, TransformersReader"
      ],
      "metadata": {
        "id": "fq2R1OXtn-pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab / No Docker environments: Start Elasticsearch from source\n",
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "es_server = Popen(\n",
        "    [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        ")\n",
        "# wait until ES has started\n",
        "! sleep 30"
      ],
      "metadata": {
        "id": "4Gu5oSG_pehJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIOQqc9rplpx",
        "outputId": "48c6cd52-fda4-4751-ab3a-b09b0f7269d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.telemetry:Haystack sends anonymous usage data to understand the actual usage and steer dev efforts towards features that are most meaningful to users. You can opt-out at anytime by calling disable_telemetry() or by manually setting the environment variable  HAYSTACK_TELEMETRY_ENABLED as described for different operating systems on the documentation page. More information at https://docs.haystack.deepset.ai/docs/telemetry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_dir = \"/content/MIMICData\"\n",
        "\n",
        "\n",
        "# Convert files to dicts\n",
        "# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\n",
        "# It must take a str as input, and return a str.\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6DaLeJ2pzVx",
        "outputId": "a4fe2cd3-174e-4e42-ab80-5548a6484959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/datafr/textAI.txt\n",
            "INFO:haystack.utils.preprocessing:Converting /content/MIMICData/datafr/AI.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[:1])\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC72vbFpp99e",
        "outputId": "fcd21ade-e3a7-4eff-e8c8-7c99ac6eb5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Document: {'content': \"On utilise le terme dintelligence artificielle ou dIA pour dsigner les ordinateurs et programmes informatiques capables de performances habituellement associes  lintelligence humaine. Par exemple, la capacit  interagir avec lhomme,  traiter de grandes quantits de donnes ou encore  apprendre progressivement et donc  samliorer de manire continue. Cest donc un vaste sujet, en perptuelle volution !\\nLintelligence artificielle peut se dfinir comme  lensemble de thories et de techniques mises en uvre en vue de raliser des machines capables de simuler lintelligence , selon le Larousse. Soit des ordinateurs ou des programmes avec des puissances de calcul capables de performances habituellement associes  lintelligence humaine, et amplifies par la technologie : \\n- Capacit de traiter de grandes quantits de donnes\\n- Facult de discerner des patterns et des modles indtectables par un humain\\n- Aptitude  comprendre et analyser ces modles\\n- Capacits  interagir avec lhomme\\n- Facult dapprendre progressivement\\n- Et damliorer continuellement ses performances\\n Lintelligence artificielle  couvre donc un vaste sujet, en perptuel mutation. Et aux progrs fulgurants depuis 1950, anne fondatrice de lIA.\\nLIA et le cloud computing au service de la pratique clinique\\nLIA est amene  prendre une place plus importante dans le quotidien des cliniciens : Du patient connect, aux outils daide  la dcision, quelles seront les tendances  venir du secteur ?\\nLintelligence artificielle aujourdhui\\nEn 2017, lintelligence artificielle a franchi une tape dcisive, parvenant  identifier les mots dans une conversation orale aussi bien quun tre humain, ouvrant de nouvelles perspectives pour la reconnaissance vocale et la traduction automatique dans la vie courante.\\nJanvier 2018, nouvelle prouesse : lIA dpasse les humains lors de diffrents dexercices de lecture et de comprhension, dans le clbre test de lecture de luniversit de Stanford. Cela permettra  lintelligence artificielle, demain, dinteragir encore plus facilement avec les humains, pour leur apporter de linformation de manire plus naturelle.\\nUne belle promesse, mais aussi une ralit trs concrte, rsume dans un sourire par Harry Shum, Executive Vice-President AI & Research de Microsoft :  Bien sr quil faut aimer lIA ! Aprs tout, quest-ce que loppos de lintelligence artificielle ? La stupidit naturelle .\\nHarry Shum, Executive Vice President de Microsoft, en charge de l'intelligence artificielle\\nHarry Shum, Executive Vice President de Microsoft, en charge de lintelligence artificielle\\n2. Comment fonctionne lintelligence artificielle ?\\nLa rvolution actuelle de lintelligence artificielle et de la science qui en dcoule est rendue possible par  une combinaison de 3 facteurs . Selon Harry Shum :  une vaste quantit de data ; une puissance informatique extraordinaire, notamment grce au cloud ; et des algorithmes rvolutionnaires, bass sur le deep-learning .\\nLIA a ainsi frquemment recours  lapprentissage supervis. Par exemple, on  nourrit  un programme avec des milliers de photos de voitures, tiquetes. Aprs cet  entrainement , le programme peut reconnatre, seul, des voitures de tous types sur les nouvelles images qui lui seront prsentes.\\nAutre composant de lintelligence artificielle, le  Machine Learning . Cette fois, on donne aux ordinateurs laccs  des donnes, puis on les laisse apprendre par eux-mmes, sans intervention humaine ou reprogrammation logicielle. Ce qui leur permet de samliorer progressivement, de manire autonome. Et de dpasser ainsi les fonctions et les capacits initialement programmes.\\nCertains algorithmes ne se contentent plus de reconnatre des images, mais se montrent capables de les produire et de donner des yeux aux machines.\", 'content_type': 'text', 'score': None, 'meta': {'name': 'textAI.txt'}, 'embedding': None, 'id': '84bda6f6d8da8c09c50201192f44b1fa'}>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import BM25Retriever\n",
        "\n",
        "retriever = BM25Retriever(document_store=document_store)"
      ],
      "metadata": {
        "id": "j75uSmjaqww4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = FARMReader(model_name_or_path=\"etalab-ia/camembert-base-squadFR-fquad-piaf\", use_gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi_PBxD-q-Eh",
        "outputId": "c44754b4-1efe-4be7-d3b7-1b762f227a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'etalab-ia/camembert-base-squadFR-fquad-piaf' (Camembert)\n",
            "INFO:haystack.modeling.model.language_model:Auto-detected model language: french\n",
            "INFO:haystack.modeling.model.language_model:Loaded 'etalab-ia/camembert-base-squadFR-fquad-piaf' (Camembert model) from model hub.\n",
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "metadata": {
        "id": "sA5zbbPArMXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can configure how many candidates the Reader and Retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(\n",
        "    query=\"Qu'est ce que intelligence artificiel?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e50c7784323d4ad8b9c9447f43f8bb09",
            "b09d5bfe81f34e8a9487c050d50ab893",
            "2ebd64ea1bbd4ad1b5021a6d96e1bbd1",
            "320ab5ae2f354f81a3ee13087d24307f",
            "7fa0656eca2c49ff953e0a9d9fe87d6a",
            "0c91c55b2fcb4cd98e5123bea3caeb8d",
            "49f0cdc0921d4dabb0d1bf7425b803f9",
            "b21e8757baa14f06bc2871bffdd1e700",
            "a26b3ccab3d345c3b0f5fa9131da3286",
            "c991cb6e23974210a354f02c35aeb889",
            "9e151923dcb9412ca02c2a680c988073"
          ]
        },
        "id": "Oe5PNbm7rQOn",
        "outputId": "faf092b8-36d7-4406-84a1-7c0afb795a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e50c7784323d4ad8b9c9447f43f8bb09"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction['answers'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22SodYhreOJ",
        "outputId": "57f8356c-8094-47f9-ce17-43c9c29a9aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Answer {'answer': 'les ordinateurs et programmes informatiques capables de performances habituellement associes  lintelligence humaine', 'type': 'extractive', 'score': 0.8493160605430603, 'context': ' dIA pour dsigner les ordinateurs et programmes informatiques capables de performances habituellement associes  lintelligence humaine. Par exemple, la', 'offsets_in_document': [{'start': 67, 'end': 182}], 'offsets_in_context': [{'start': 18, 'end': 133}], 'document_id': '84bda6f6d8da8c09c50201192f44b1fa', 'meta': {'name': 'textAI.txt'}}>,\n",
            " <Answer {'answer': \"un  ensemble de thories et de techniques mises en uvre en vue de raliser des machines capables de simuler l'intelligence humaine\", 'type': 'extractive', 'score': 0.7839241623878479, 'context': \"e (IA) est un  ensemble de thories et de techniques mises en uvre en vue de raliser des machines capables de simuler l'intelligence humaine 1.\\nElle en\", 'offsets_in_document': [{'start': 37, 'end': 165}], 'offsets_in_context': [{'start': 11, 'end': 139}], 'document_id': '726cd64121cb069851be6e3172472be8', 'meta': {'name': 'AI.txt'}}>,\n",
            " <Answer {'answer': 'dinteragir encore plus facilement avec les humains, pour leur apporter de linformation de manire plus naturelle', 'type': 'extractive', 'score': 0.43755269050598145, 'context': 'tificielle, demain, dinteragir encore plus facilement avec les humains, pour leur apporter de linformation de manire plus naturelle.\\nUne belle promess', 'offsets_in_document': [{'start': 1968, 'end': 2079}], 'offsets_in_context': [{'start': 20, 'end': 131}], 'document_id': '84bda6f6d8da8c09c50201192f44b1fa', 'meta': {'name': 'textAI.txt'}}>,\n",
            " <Answer {'answer': 'Machine Learning', 'type': 'extractive', 'score': 0.32273176312446594, 'context': 'eront prsentes.\\nAutre composant de lintelligence artificielle, le  Machine Learning . Cette fois, on donne aux ordinateurs laccs  des donnes, puis on ', 'offsets_in_document': [{'start': 3236, 'end': 3252}], 'offsets_in_context': [{'start': 67, 'end': 83}], 'document_id': '84bda6f6d8da8c09c50201192f44b1fa', 'meta': {'name': 'textAI.txt'}}>,\n",
            " <Answer {'answer': 'Elle utilise des mthodes de rsolution de problmes  forte complexit logique ou algorithmique', 'type': 'extractive', 'score': 0.1754876971244812, 'context': 'tiques et de la philosophie). Elle utilise des mthodes de rsolution de problmes  forte complexit logique ou algorithmique. Par extension, elle compren', 'offsets_in_document': [{'start': 650, 'end': 741}], 'offsets_in_context': [{'start': 30, 'end': 121}], 'document_id': '726cd64121cb069851be6e3172472be8', 'meta': {'name': 'AI.txt'}}>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import DocumentSearchPipeline\n",
        "pipeline = DocumentSearchPipeline(retriever)\n",
        "query = 'IA '\n",
        "result = pipeline.run(query, params={\"Retriever\": {\"top_k\": 10}})\n"
      ],
      "metadata": {
        "id": "WC1fC2z1rmgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import print_documents\n",
        "\n",
        "print_documents(result, max_text_len=100, print_name=True, print_meta=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiWVMn6ctMXi",
        "outputId": "e5c2a613-860c-4398-c938-1497f3e982f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: IA \n",
            "\n",
            "{   'content': \"L'intelligence artificielle (IA) est un  ensemble de thories \"\n",
            "               'et de techniques mises en uvre en vue d...',\n",
            "    'meta': {'name': 'AI.txt'},\n",
            "    'name': 'AI.txt'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x.to_dict() for x in result[\"documents\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaNq58GKuUOa",
        "outputId": "0ae999a8-85b5-4aff-d064-148a9457f3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': \"L'intelligence artificielle (IA) est un  ensemble de thories et de techniques mises en uvre en vue de raliser des machines capables de simuler l'intelligence humaine 1.\\nElle englobe donc un ensemble de concepts et de technologies, plus qu'une discipline autonome constitue2. Des instances, telle la CNIL, notant le peu de prcision de la dfinition de l'IA, l'ont prsente comme  le grand mythe de notre temps 3.\\nSouvent classe dans le groupe des mathmatiques et des sciences cognitives, elle fait appel  la neurobiologie computationnelle (particulirement aux rseaux neuronaux) et  la logique mathmatique (partie des mathmatiques et de la philosophie). Elle utilise des mthodes de rsolution de problmes  forte complexit logique ou algorithmique. Par extension, elle comprend, dans le langage courant, les dispositifs imitant ou remplaant l'homme dans certaines mises en uvre de ses fonctions cognitives4.\\nSes finalits et enjeux ainsi que son dveloppement suscitent, depuis l'apparition du concept, de nombreuses interprtations, fantasmes ou inquitudes s'exprimant tant dans les rcits ou films de science-fiction que dans les essais philosophiques5. Si des outils relevant d'intelligences artificielles spcialises ont fait leurs preuves, la ralit semble encore tenir l'intelligence artificielle gnraliste loin des performances du vivant ; ainsi, l'IA reste encore bien infrieure au chat dans toutes ses aptitudes naturelles6.\",\n",
              "  'content_type': 'text',\n",
              "  'score': 0.5265504964968136,\n",
              "  'meta': {'name': 'AI.txt'},\n",
              "  'embedding': None,\n",
              "  'id': '726cd64121cb069851be6e3172472be8'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5uyEwZSud6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}