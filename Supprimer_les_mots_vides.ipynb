{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LudhVQtoY6s"
      },
      "source": [
        "# **Methode 1: Natural Language Processing**\n",
        "\n",
        "nlkt peut être utilisé pour supprimer les mots vides du texte en Python. Il contient des mots vides de plusieurs langues différentes.\n",
        "\n",
        "Le code suivant montre comment supprimer les mots vides avec ce package. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVYyr97Epbf5",
        "outputId": "3bf17ea6-dab2-4986-9601-091731e17b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0DcwmTUoYbr"
      },
      "outputs": [],
      "source": [
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV6S39pgp4wb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zykSr1ilsHf1",
        "outputId": "bf357a6c-348e-4390-9877-234d19524d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb2AbywisiOr"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        " What is artificial intelligence?  \"\"\"\n",
        "\n",
        "tokens = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goFrmO-rp5ne"
      },
      "outputs": [],
      "source": [
        "tokens_without_sw= [word for word in tokens if word not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qXieSQ-tHxt",
        "outputId": "31c1a73b-0371-41bc-a157-1c598b45ae66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What', 'artificial', 'intelligence', '?']\n"
          ]
        }
      ],
      "source": [
        "print(tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STcNLwmAztzw",
        "outputId": "2ddb8241-4738-4e79-c1bc-249803ef1e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What', 'artificial', 'intelligence', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokens_without_sw\n",
        "code_block = ' '.join(tokens)\n",
        "print(code_block)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEz2Bl-pzO2k",
        "outputId": "0b8a2135-6871-4f87-edc8-3618fed991b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What artificial intelligence ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IyX_H4NycN4"
      },
      "source": [
        "# **Methode 2: stop-words**\n",
        "\n",
        "Le package stop-words est utilisé pour supprimer les mots vides du texte en Python. Ce paquet contient des mots vides dans de nombreuses langues comme l’anglais, le danois, le français, l’espagnol et plus encore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e-iRAPgy2Ka",
        "outputId": "0698e08a-bf2f-4321-b910-5f844fa55b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: stop_words\n",
            "  Building wheel for stop_words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=cb1fcc3aabbcf99a09d0bb3dc8deb3e7377057a493980477308cf11a9601a551\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/03/0d/3bd31c983789aeb0b4d5e2ca48590288d9db1586cf5f225062\n",
            "Successfully built stop_words\n",
            "Installing collected packages: stop_words\n",
            "Successfully installed stop_words-2018.7.23\n"
          ]
        }
      ],
      "source": [
        "pip install stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWFPSv20yk5d",
        "outputId": "b1110ebe-6d9c-4dba-cc12-e9dd88ba2928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"C'est\", 'quoi', \"l'intelligence\", 'artificielle', '?']\n"
          ]
        }
      ],
      "source": [
        "from stop_words import get_stop_words\n",
        "A = [word for word in tokens if word not in get_stop_words('french')]\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdIqMYTu2Yu"
      },
      "source": [
        "# **Methode 3: remove_stpwrds()**\n",
        "\n",
        "La méthode remove_stpwrds() de la bibliothèque textcleaner est utilisée pour supprimer les mots vides du texte en Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JJ3BL-wvavW",
        "outputId": "2372f9a0-5d21-4b33-a642-89f183b50aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textcleaner\n",
            "  Downloading textcleaner-0.4.26.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from textcleaner) (3.7)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from textcleaner) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->textcleaner) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->textcleaner) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->textcleaner) (4.64.1)\n",
            "Building wheels for collected packages: textcleaner\n",
            "  Building wheel for textcleaner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textcleaner: filename=textcleaner-0.4.26-py3-none-any.whl size=4737 sha256=1478bd82366209ab7408c7f6ad0fd82ffb5efb38a4561647555bd241329b009d\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/f4/c4/9284af2d3be0674e9637abca7cfb1d3ee982ab5208075fb833\n",
            "Successfully built textcleaner\n",
            "Installing collected packages: textcleaner\n",
            "Successfully installed textcleaner-0.4.26\n"
          ]
        }
      ],
      "source": [
        "pip install textcleaner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GjL7fMPvOGS",
        "outputId": "c60e29c9-2548-4bed-9c33-4cbcd619196b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C'est\n",
            "quoi\n",
            "l'intelligence\n",
            "artificielle\n",
            "?\n"
          ]
        }
      ],
      "source": [
        "import textcleaner as tc\n",
        "data = tc.document(tokens)\n",
        "print(data.remove_stpwrds())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uKCqk7a30fV"
      },
      "source": [
        "La bibliothèque gensim possède aussi un outil remove_stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42rDWoe-ylMm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "def clean_sentence(sentence, stopwords=False):\n",
        "  sentence = sentence.lower().strip()\n",
        "  sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "  if stopwords:\n",
        "    sentence = remove_stopwords(sentence)\n",
        "  return sentence\n",
        "\n",
        "def get_cleaned_sentences(tokens, stopwords=False):\n",
        "  cleaned_sentences = []\n",
        "  for row in tokens:\n",
        "    cleaned = clean_sentence(row, stopwords)\n",
        "    cleaned_sentences.append(cleaned)\n",
        "  return cleaned_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XLbF6K349Wz",
        "outputId": "c643c518-7fa5-402e-f82c-885363744459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', 'chatbot', '', '', 'automated', 'program', '', 'interacts', '', 'customers', '', '', 'human', '', '', 'costs', 'little', '', '', '', 'engage', '', '', 'chatbots', 'attend', '', 'customers', '', '', 'times', '', '', 'day', '', 'week', '', '', '', 'limited', '', 'time', '', '', 'physical', 'location', '', '', 'makes', '', 'implementation', 'appealing', '', '', 'lot', '', 'businesses', '', '', '', '', '', 'manpower', '', 'financial', 'resources', '', '', 'employees', 'working', '', '', 'clock', '', 'chatbots', '', 'convenient', '', 'providing', 'customer', 'service', '', 'support', '24', 'hours', '', 'day', '', '7', 'days', '', 'week', '', '', '', 'free', '', 'phone', 'lines', '', '', 'far', '', 'expensive', '', '', 'long', 'run', '', 'hiring', 'people', '', 'perform', 'support', '', '', 'ai', '', 'natural', 'language', 'processing', '', 'chatbots', '', '', 'better', '', 'understanding', '', 'customers', 'want', '', 'providing', '', 'help', '', 'need', '', 'companies', '', 'like', 'chatbots', '', '', '', 'collect', 'data', '', 'customer', 'queries', '', 'response', 'times', '', 'satisfaction', '', '', '', '', '', 'chatbots', '', '', '', '', '', 'limited', '', '', '', 'natural', 'language', 'processing', '', '', '', '', 'fully', 'comprehend', '', 'customer', 's', 'input', '', '', 'provide', 'incoherent', 'answers', '', '', 'chatbots', '', '', 'limited', '', '', 'scope', '', 'queries', '', '', '', 'able', '', 'respond', '', '', '', '', 'lead', '', 'frustration', '', '', 'lack', '', 'emotion', '', 'sympathy', '', '', 'personalization', 'given', 'fairly', 'generic', 'feedback', '', '', 'addition', '', 'customer', 'dissatisfaction', '', '', 'reaching', '', 'human', '', '', 'chatbots', '', '', 'expensive', '', 'implement', '', 'maintain', '', 'especially', '', '', '', '', 'customized', '', 'updated', '', '']\n"
          ]
        }
      ],
      "source": [
        "cleaned_sentences = get_cleaned_sentences(tokens, stopwords=True)\n",
        "print(cleaned_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LX6pbLp7kLX"
      },
      "source": [
        "# **Named entity recognition**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIis1RPi8JEI"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ncisJyS7on_"
      },
      "outputs": [],
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cRyQPxd7uC5"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "9lM-_kFu7uJc",
        "outputId": "234271c9-ed21-48ef-eaed-5ba7fd7a8509"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>A chatbot is an automated program that interacts with customers as a human would and costs little to nothing to engage with. Chatbots attend to customers at all times of \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the day and week\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " and are not limited by time or a physical location. This makes its implementation appealing to a lot of businesses that may not have the manpower or financial resources to keep employees working around the clock. </br>Chatbots are convenient for providing customer service and support \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    24 hours\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " a day, \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    7 days\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " a week. They also free up phone lines and are far less expensive over the long run than hiring people to perform support. Using \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    AI\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " and natural language processing, chatbots are becoming better at understanding what customers want and providing the help they need. Companies also like chatbots because they can collect data about customer queries, response times, satisfaction, and so on.</br></br>Chatbots, however, are still limited. Even with natural language processing, they may not fully comprehend a customer's input and may provide incoherent answers. Many chatbots are also limited in the scope of queries that they are able to respond to. This may lead to frustration with a lack of emotion, sympathy, and personalization given fairly generic feedback. In addition to customer dissatisfaction with not reaching a human being, chatbots can be expensive to implement and maintain, especially if they must be customized and updated often.</br></div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(nlp(doc.text),style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8qQIkM7uNN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaIYtfWw7uQk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}